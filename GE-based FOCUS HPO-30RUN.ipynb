{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279339a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce2d7ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Any, Callable, Union\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, LabelEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1231\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\awwal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\__init__.py:147\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(name):\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\awwal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\awwal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\__init__.py:631\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_page_trend_test\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m page_trend_test\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mannwhitneyu\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mannwhitneyu\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bws_test\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bws_test\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fit, goodness_of_fit\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_covariance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Covariance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1178\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1140\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1080\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1504\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1476\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1645\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:161\u001b[39m, in \u001b[36m_path_isfile\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:153\u001b[39m, in \u001b[36m_path_is_mode_type\u001b[39m\u001b[34m(path, mode)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Grammatical Evolution (GE) TabNet & Baseline Models Hyperparameter Optimization\n",
    "================================================================================\n",
    "\n",
    "MODIFIED VERSION - 30 Independent Runs per Model\n",
    "- 30 independent GE runs per model for statistical robustness\n",
    "- GE_POP_SIZE: 200\n",
    "- GE_GENERATIONS: 50 (both TabNet and baselines)\n",
    "- Data Split: 80/10/10 train/validation/test\n",
    "\n",
    "Usage:\n",
    "    python ge_hpo_30runs.py\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any, Callable, Union\n",
    "from dataclasses import dataclass, field\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
    ")\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    import torch\n",
    "    TABNET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TABNET_AVAILABLE = False\n",
    "    print(\"TabNet not available\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available\")\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    SMOTE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SMOTE_AVAILABLE = False\n",
    "    print(\"SMOTE not available\")\n",
    "\n",
    "print(\"GE-based HPO loaded (30 Independent Runs Version)\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STATISTICAL UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def compute_confidence_interval(data: np.ndarray, confidence: float = 0.95) -> Tuple[float, float]:\n",
    "    if len(data) < 2:\n",
    "        return (np.mean(data), np.mean(data))\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    se = stats.sem(data)\n",
    "    h = se * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return (mean - h, mean + h)\n",
    "\n",
    "\n",
    "def compute_statistics(data: np.ndarray) -> Dict[str, float]:\n",
    "    if len(data) == 0:\n",
    "        return {'mean': 0, 'std': 0, 'min': 0, 'max': 0, 'median': 0, 'ci_lower': 0, 'ci_upper': 0}\n",
    "    ci_lower, ci_upper = compute_confidence_interval(data)\n",
    "    return {\n",
    "        'mean': float(np.mean(data)),\n",
    "        'std': float(np.std(data)),\n",
    "        'min': float(np.min(data)),\n",
    "        'max': float(np.max(data)),\n",
    "        'median': float(np.median(data)),\n",
    "        'ci_lower': float(ci_lower),\n",
    "        'ci_upper': float(ci_upper)\n",
    "    }\n",
    "\n",
    "\n",
    "def paired_ttest(scores1: np.ndarray, scores2: np.ndarray) -> Tuple[float, float]:\n",
    "    if len(scores1) != len(scores2) or len(scores1) < 2:\n",
    "        return (np.nan, np.nan)\n",
    "    t_stat, p_value = stats.ttest_rel(scores1, scores2)\n",
    "    return (float(t_stat), float(p_value))\n",
    "\n",
    "\n",
    "def wilcoxon_test(scores1: np.ndarray, scores2: np.ndarray) -> Tuple[float, float]:\n",
    "    if len(scores1) != len(scores2) or len(scores1) < 2:\n",
    "        return (np.nan, np.nan)\n",
    "    try:\n",
    "        stat, p_value = stats.wilcoxon(scores1, scores2)\n",
    "        return (float(stat), float(p_value))\n",
    "    except:\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# GRAMMATICAL EVOLUTION CORE\n",
    "# =============================================================================\n",
    "\n",
    "class HyperparameterGrammar:\n",
    "    def __init__(self, grammar_str: str = None):\n",
    "        self.params = {}\n",
    "        self.param_order = []\n",
    "        if grammar_str:\n",
    "            self._parse_string(grammar_str)\n",
    "    \n",
    "    def _parse_string(self, grammar_str: str):\n",
    "        for line in grammar_str.strip().split('\\n'):\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            if '::=' in line:\n",
    "                parts = line.split('::=')\n",
    "                param = parts[0].strip().strip('<>').replace('-', '_').replace(' ', '')\n",
    "                choices = [c.strip() for c in parts[1].strip().split('|') if c.strip()]\n",
    "                self.params[param] = choices\n",
    "                self.param_order.append(param)\n",
    "    \n",
    "    def get_choices(self, param: str) -> List[str]:\n",
    "        return self.params.get(param.strip('<>').replace('-', '_'), [])\n",
    "    \n",
    "    def n_choices(self, param: str) -> int:\n",
    "        return len(self.get_choices(param))\n",
    "    \n",
    "    def total_search_space(self) -> int:\n",
    "        space = 1\n",
    "        for choices in self.params.values():\n",
    "            space *= len(choices)\n",
    "        return space\n",
    "\n",
    "\n",
    "def _convert_value(value_str: str) -> Any:\n",
    "    value_str = str(value_str).strip()\n",
    "    if value_str.lower() == 'true': return True\n",
    "    if value_str.lower() == 'false': return False\n",
    "    if value_str.lower() == 'none': return None\n",
    "    try:\n",
    "        if 'e' in value_str.lower() or '.' in value_str:\n",
    "            return float(value_str)\n",
    "        return int(value_str)\n",
    "    except ValueError:\n",
    "        return value_str\n",
    "\n",
    "\n",
    "class GEMapper:\n",
    "    def __init__(self, grammar: HyperparameterGrammar, max_wraps: int = 2):\n",
    "        self.grammar = grammar\n",
    "        self.max_wraps = max_wraps\n",
    "    \n",
    "    def decode(self, chromosome: List[int]) -> Tuple[Dict[str, Any], bool]:\n",
    "        config = {}\n",
    "        codon_idx = 0\n",
    "        wraps = 0\n",
    "        \n",
    "        for param in self.grammar.param_order:\n",
    "            choices = self.grammar.get_choices(param)\n",
    "            if not choices:\n",
    "                continue\n",
    "            if codon_idx >= len(chromosome):\n",
    "                codon_idx = 0\n",
    "                wraps += 1\n",
    "                if wraps > self.max_wraps:\n",
    "                    return config, False\n",
    "            codon = chromosome[codon_idx]\n",
    "            choice_idx = codon % len(choices)\n",
    "            config[param] = _convert_value(choices[choice_idx])\n",
    "            codon_idx += 1\n",
    "        return config, True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GEResult:\n",
    "    best_config: Dict[str, Any]\n",
    "    best_fitness: float\n",
    "    best_chromosome: List[int]\n",
    "    history: Dict[str, List]\n",
    "    generations: int\n",
    "    evaluations: int\n",
    "    runtime_seconds: float\n",
    "\n",
    "\n",
    "class GEOptimizer:\n",
    "    def __init__(self, grammar: HyperparameterGrammar, fitness_fn: Callable,\n",
    "                 pop_size: int = 200, generations: int = 50,\n",
    "                 chromosome_length: int = None, codon_max: int = 255,\n",
    "                 crossover_rate: float = 0.8, mutation_rate: float = 0.1,\n",
    "                 tournament_size: int = 3, elitism: int = 2,\n",
    "                 maximize: bool = True, seed: int = None, verbose: bool = False):\n",
    "        \n",
    "        self.grammar = grammar\n",
    "        self.mapper = GEMapper(grammar)\n",
    "        self.fitness_fn = fitness_fn\n",
    "        self.pop_size = pop_size\n",
    "        self.generations = generations\n",
    "        self.codon_max = codon_max\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.tournament_size = tournament_size\n",
    "        self.elitism = elitism\n",
    "        self.maximize = maximize\n",
    "        self.verbose = verbose\n",
    "        self.chromosome_length = chromosome_length or max(len(grammar.param_order) * 3, 20)\n",
    "        \n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.history = {'best_fitness': [], 'avg_fitness': []}\n",
    "    \n",
    "    def _init_population(self) -> List[List[int]]:\n",
    "        return [[random.randint(0, self.codon_max) for _ in range(self.chromosome_length)]\n",
    "                for _ in range(self.pop_size)]\n",
    "    \n",
    "    def _evaluate(self, chrom: List[int]) -> Tuple[float, Dict, bool]:\n",
    "        config, valid = self.mapper.decode(chrom)\n",
    "        if not valid:\n",
    "            return -float('inf') if self.maximize else float('inf'), config, False\n",
    "        try:\n",
    "            fitness = self.fitness_fn(config)\n",
    "            return fitness, config, True\n",
    "        except:\n",
    "            return -float('inf') if self.maximize else float('inf'), config, False\n",
    "    \n",
    "    def _tournament(self, pop: List[List[int]], scores: List[float]) -> List[int]:\n",
    "        indices = random.sample(range(len(pop)), self.tournament_size)\n",
    "        if self.maximize:\n",
    "            winner = max(indices, key=lambda i: scores[i])\n",
    "        else:\n",
    "            winner = min(indices, key=lambda i: scores[i])\n",
    "        return list(pop[winner])\n",
    "    \n",
    "    def _crossover(self, p1: List[int], p2: List[int]) -> Tuple[List[int], List[int]]:\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return p1[:], p2[:]\n",
    "        pt = random.randint(1, len(p1) - 1)\n",
    "        return p1[:pt] + p2[pt:], p2[:pt] + p1[pt:]\n",
    "    \n",
    "    def _mutate(self, chrom: List[int]) -> List[int]:\n",
    "        for i in range(len(chrom)):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                chrom[i] = random.randint(0, self.codon_max)\n",
    "        return chrom\n",
    "    \n",
    "    def evolve(self) -> GEResult:\n",
    "        start_time = time.time()\n",
    "        population = self._init_population()\n",
    "        best_ever = (None, -float('inf') if self.maximize else float('inf'), None)\n",
    "        total_evals = 0\n",
    "        \n",
    "        for gen in range(self.generations):\n",
    "            scores = []\n",
    "            configs = []\n",
    "            for chrom in population:\n",
    "                fit, cfg, valid = self._evaluate(chrom)\n",
    "                scores.append(fit)\n",
    "                configs.append(cfg)\n",
    "            total_evals += len(population)\n",
    "            \n",
    "            valid_scores = [s for s in scores if s != -float('inf') and s != float('inf')]\n",
    "            if valid_scores:\n",
    "                if self.maximize:\n",
    "                    best_idx = np.argmax(scores)\n",
    "                    if scores[best_idx] > best_ever[1]:\n",
    "                        best_ever = (list(population[best_idx]), scores[best_idx], configs[best_idx])\n",
    "                else:\n",
    "                    best_idx = np.argmin(scores)\n",
    "                    if scores[best_idx] < best_ever[1]:\n",
    "                        best_ever = (list(population[best_idx]), scores[best_idx], configs[best_idx])\n",
    "                \n",
    "                best_fit = max(valid_scores) if self.maximize else min(valid_scores)\n",
    "                avg_fit = np.mean(valid_scores)\n",
    "            else:\n",
    "                best_fit = avg_fit = 0\n",
    "            \n",
    "            self.history['best_fitness'].append(best_fit)\n",
    "            self.history['avg_fitness'].append(avg_fit)\n",
    "            \n",
    "            if self.verbose and (gen % 10 == 0 or gen == self.generations - 1):\n",
    "                print(f\"  Gen {gen:3d}: Best={best_fit:.4f}, Avg={avg_fit:.4f}, Overall={best_ever[1]:.4f}\")\n",
    "            \n",
    "            sorted_pop = sorted(zip(population, scores), key=lambda x: x[1], reverse=self.maximize)\n",
    "            new_pop = [list(sorted_pop[i][0]) for i in range(self.elitism)]\n",
    "            \n",
    "            while len(new_pop) < self.pop_size:\n",
    "                p1 = self._tournament(population, scores)\n",
    "                p2 = self._tournament(population, scores)\n",
    "                c1, c2 = self._crossover(p1, p2)\n",
    "                new_pop.append(self._mutate(c1))\n",
    "                if len(new_pop) < self.pop_size:\n",
    "                    new_pop.append(self._mutate(c2))\n",
    "            \n",
    "            population = new_pop\n",
    "        \n",
    "        runtime = time.time() - start_time\n",
    "        return GEResult(\n",
    "            best_config=best_ever[2],\n",
    "            best_fitness=best_ever[1],\n",
    "            best_chromosome=best_ever[0],\n",
    "            history=self.history,\n",
    "            generations=len(self.history['best_fitness']),\n",
    "            evaluations=total_evals,\n",
    "            runtime_seconds=runtime\n",
    "        )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HYPERPARAMETER GRAMMARS\n",
    "# =============================================================================\n",
    "\n",
    "def create_tabnet_grammar() -> HyperparameterGrammar:\n",
    "    return HyperparameterGrammar(grammar_str=\"\"\"\n",
    "<n_d> ::= 8 | 16 | 32 | 64 | 128\n",
    "<n_a> ::= 8 | 16 | 32 | 64 | 128\n",
    "<n_steps> ::= 3 | 5 | 7 | 10\n",
    "<lambda_sparse> ::= 1e-5 | 1e-4 | 1e-3 | 1e-2\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def create_random_forest_grammar() -> HyperparameterGrammar:\n",
    "    return HyperparameterGrammar(grammar_str=\"\"\"\n",
    "<n_estimators> ::= 100 | 200 | 300 | 500\n",
    "<max_depth> ::= 5 | 10 | 15 | 20 | None\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def create_xgboost_grammar() -> HyperparameterGrammar:\n",
    "    return HyperparameterGrammar(grammar_str=\"\"\"\n",
    "<n_estimators> ::= 100 | 200 | 300 | 500\n",
    "<learning_rate> ::= 0.01 | 0.05 | 0.1 | 0.2\n",
    "<max_depth> ::= 3 | 5 | 7 | 9\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def create_svm_grammar() -> HyperparameterGrammar:\n",
    "    return HyperparameterGrammar(grammar_str=\"\"\"\n",
    "<C> ::= 0.1 | 1.0 | 10.0 | 100.0\n",
    "<kernel> ::= linear | rbf | poly\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def create_logistic_regression_grammar() -> HyperparameterGrammar:\n",
    "    return HyperparameterGrammar(grammar_str=\"\"\"\n",
    "<C> ::= 0.01 | 0.1 | 1.0 | 10.0 | 100.0\n",
    "<penalty> ::= l1 | l2\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def create_gradient_boosting_grammar() -> HyperparameterGrammar:\n",
    "    return HyperparameterGrammar(grammar_str=\"\"\"\n",
    "<n_estimators> ::= 100 | 200 | 300 | 500\n",
    "<learning_rate> ::= 0.01 | 0.05 | 0.1 | 0.2\n",
    "<max_depth> ::= 3 | 5 | 7\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    DATA_CSV: str = r\"C:\\Users\\awwal\\Desktop\\MLEA_experiments\\data.csv\"\n",
    "    TARGET_COLUMN: str = \"diagnosis\"\n",
    "    \n",
    "    TEST_SIZE: float = 0.1\n",
    "    VAL_SIZE: float = 1/9\n",
    "    \n",
    "    # GE Parameters - MODIFIED\n",
    "    GE_POP_SIZE: int = 200\n",
    "    GE_GENERATIONS: int = 50\n",
    "    GE_GENERATIONS_BASELINE: int = 50\n",
    "    GE_CROSSOVER_RATE: float = 0.8\n",
    "    GE_MUTATION_RATE: float = 0.1\n",
    "    GE_TOURNAMENT_SIZE: int = 3\n",
    "    GE_ELITISM: int = 2\n",
    "    \n",
    "    # Number of independent runs - NEW\n",
    "    N_INDEPENDENT_RUNS: int = 30\n",
    "    \n",
    "    # TabNet\n",
    "    TABNET_MAX_EPOCHS: int = 100\n",
    "    TABNET_PATIENCE: int = 15\n",
    "    TABNET_BATCH_SIZE: int = 256\n",
    "    TABNET_GAMMA: float = 1.3\n",
    "    \n",
    "    # CV\n",
    "    CV_FOLDS: int = 5\n",
    "    USE_CV: bool = True\n",
    "    USE_SMOTE: bool = True\n",
    "    \n",
    "    RESULTS_DIR: str = \"ge_results_30runs\"\n",
    "    RANDOM_SEED: int = 42\n",
    "    VERBOSE: bool = True\n",
    "    \n",
    "    SAVE_PLOTS: bool = True\n",
    "    SHOW_PLOTS: bool = True\n",
    "    PLOT_DPI: int = 150\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL OPTIMIZERS\n",
    "# =============================================================================\n",
    "\n",
    "class TabNetOptimizer:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, config: Config):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.config = config\n",
    "        \n",
    "        self.X_full = np.vstack([X_train, X_val])\n",
    "        self.y_full = np.concatenate([y_train, y_val])\n",
    "        self.cv = StratifiedKFold(n_splits=config.CV_FOLDS, shuffle=True, \n",
    "                                  random_state=config.RANDOM_SEED)\n",
    "    \n",
    "    def _fitness_cv(self, params: Dict, seed_offset: int = 0) -> float:\n",
    "        try:\n",
    "            cv_scores = []\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(self.cv.split(self.X_full, self.y_full)):\n",
    "                X_tr, X_v = self.X_full[train_idx], self.X_full[val_idx]\n",
    "                y_tr, y_v = self.y_full[train_idx], self.y_full[val_idx]\n",
    "                \n",
    "                if self.config.USE_SMOTE and SMOTE_AVAILABLE:\n",
    "                    smote = SMOTE(random_state=self.config.RANDOM_SEED + seed_offset + fold_idx)\n",
    "                    X_tr, y_tr = smote.fit_resample(X_tr, y_tr)\n",
    "                \n",
    "                model = TabNetClassifier(\n",
    "                    n_d=params['n_d'],\n",
    "                    n_a=params['n_a'],\n",
    "                    n_steps=params['n_steps'],\n",
    "                    gamma=self.config.TABNET_GAMMA,\n",
    "                    lambda_sparse=params['lambda_sparse'],\n",
    "                    verbose=0,\n",
    "                    seed=self.config.RANDOM_SEED + seed_offset + fold_idx\n",
    "                )\n",
    "                \n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_v, y_v)],\n",
    "                    eval_metric=['auc'],\n",
    "                    max_epochs=self.config.TABNET_MAX_EPOCHS,\n",
    "                    patience=self.config.TABNET_PATIENCE,\n",
    "                    batch_size=self.config.TABNET_BATCH_SIZE,\n",
    "                    drop_last=False\n",
    "                )\n",
    "                \n",
    "                y_pred_proba = model.predict_proba(X_v)[:, 1]\n",
    "                cv_scores.append(roc_auc_score(y_v, y_pred_proba))\n",
    "            \n",
    "            return np.mean(cv_scores)\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def optimize_single_run(self, run_idx: int) -> Tuple[Dict, float, GEResult]:\n",
    "        grammar = create_tabnet_grammar()\n",
    "        seed = self.config.RANDOM_SEED + run_idx * 1000\n",
    "        \n",
    "        fitness_fn = lambda p: self._fitness_cv(p, seed_offset=run_idx * 100)\n",
    "        \n",
    "        optimizer = GEOptimizer(\n",
    "            grammar=grammar,\n",
    "            fitness_fn=fitness_fn,\n",
    "            pop_size=self.config.GE_POP_SIZE,\n",
    "            generations=self.config.GE_GENERATIONS,\n",
    "            crossover_rate=self.config.GE_CROSSOVER_RATE,\n",
    "            mutation_rate=self.config.GE_MUTATION_RATE,\n",
    "            tournament_size=self.config.GE_TOURNAMENT_SIZE,\n",
    "            elitism=self.config.GE_ELITISM,\n",
    "            maximize=True,\n",
    "            seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        result = optimizer.evolve()\n",
    "        result.best_config['gamma'] = self.config.TABNET_GAMMA\n",
    "        return result.best_config, result.best_fitness, result\n",
    "\n",
    "\n",
    "class BaselineOptimizer:\n",
    "    MODEL_GRAMMARS = {\n",
    "        'RandomForest': create_random_forest_grammar,\n",
    "        'LogisticRegression': create_logistic_regression_grammar,\n",
    "        'SVM': create_svm_grammar,\n",
    "        'GradientBoosting': create_gradient_boosting_grammar,\n",
    "        'XGBoost': create_xgboost_grammar,\n",
    "    }\n",
    "    \n",
    "    FIXED_PARAMS = {\n",
    "        'RandomForest': {'max_features': 'sqrt', 'min_samples_split': 2},\n",
    "        'LogisticRegression': {'max_iter': 1000},\n",
    "        'SVM': {'gamma': 'scale'},\n",
    "        'GradientBoosting': {'subsample': 0.8},\n",
    "        'XGBoost': {'subsample': 0.8, 'colsample_bytree': 0.8},\n",
    "    }\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_val, y_val, config: Config):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.config = config\n",
    "        \n",
    "        self.X_full = np.vstack([X_train, X_val])\n",
    "        self.y_full = np.concatenate([y_train, y_val])\n",
    "        self.cv = StratifiedKFold(n_splits=config.CV_FOLDS, shuffle=True,\n",
    "                                  random_state=config.RANDOM_SEED)\n",
    "    \n",
    "    def _create_model(self, model_type: str, params: Dict, seed: int):\n",
    "        full_params = {**self.FIXED_PARAMS.get(model_type, {}), **params}\n",
    "        \n",
    "        if model_type == 'RandomForest':\n",
    "            max_depth = full_params.get('max_depth')\n",
    "            if max_depth == 'None' or max_depth is None:\n",
    "                max_depth = None\n",
    "            return RandomForestClassifier(\n",
    "                n_estimators=full_params['n_estimators'],\n",
    "                max_depth=max_depth,\n",
    "                max_features=full_params.get('max_features', 'sqrt'),\n",
    "                random_state=seed,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        \n",
    "        elif model_type == 'LogisticRegression':\n",
    "            penalty = full_params.get('penalty', 'l2')\n",
    "            solver = 'liblinear' if penalty == 'l1' else 'lbfgs'\n",
    "            return LogisticRegression(\n",
    "                C=full_params['C'],\n",
    "                penalty=penalty,\n",
    "                solver=solver,\n",
    "                max_iter=full_params.get('max_iter', 1000),\n",
    "                random_state=seed\n",
    "            )\n",
    "        \n",
    "        elif model_type == 'SVM':\n",
    "            return SVC(\n",
    "                C=full_params['C'],\n",
    "                kernel=full_params['kernel'],\n",
    "                gamma=full_params.get('gamma', 'scale'),\n",
    "                probability=True,\n",
    "                random_state=seed\n",
    "            )\n",
    "        \n",
    "        elif model_type == 'GradientBoosting':\n",
    "            return GradientBoostingClassifier(\n",
    "                n_estimators=full_params['n_estimators'],\n",
    "                learning_rate=full_params['learning_rate'],\n",
    "                max_depth=full_params['max_depth'],\n",
    "                subsample=full_params.get('subsample', 0.8),\n",
    "                random_state=seed\n",
    "            )\n",
    "        \n",
    "        elif model_type == 'XGBoost':\n",
    "            if not XGBOOST_AVAILABLE:\n",
    "                raise ImportError(\"XGBoost not available\")\n",
    "            return XGBClassifier(\n",
    "                n_estimators=full_params['n_estimators'],\n",
    "                learning_rate=full_params['learning_rate'],\n",
    "                max_depth=full_params['max_depth'],\n",
    "                subsample=full_params.get('subsample', 0.8),\n",
    "                colsample_bytree=full_params.get('colsample_bytree', 0.8),\n",
    "                random_state=seed,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss',\n",
    "                verbosity=0\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_type}\")\n",
    "    \n",
    "    def _fitness_cv(self, model_type: str, params: Dict, seed_offset: int = 0) -> float:\n",
    "        try:\n",
    "            seed = self.config.RANDOM_SEED + seed_offset\n",
    "            model = self._create_model(model_type, params, seed)\n",
    "            \n",
    "            cv_scores = []\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(self.cv.split(self.X_full, self.y_full)):\n",
    "                X_tr, X_v = self.X_full[train_idx], self.X_full[val_idx]\n",
    "                y_tr, y_v = self.y_full[train_idx], self.y_full[val_idx]\n",
    "                \n",
    "                if self.config.USE_SMOTE and SMOTE_AVAILABLE:\n",
    "                    smote = SMOTE(random_state=seed + fold_idx)\n",
    "                    X_tr, y_tr = smote.fit_resample(X_tr, y_tr)\n",
    "                \n",
    "                model_clone = clone(model)\n",
    "                model_clone.fit(X_tr, y_tr)\n",
    "                \n",
    "                if hasattr(model_clone, 'predict_proba'):\n",
    "                    y_pred_proba = model_clone.predict_proba(X_v)[:, 1]\n",
    "                    cv_scores.append(roc_auc_score(y_v, y_pred_proba))\n",
    "                else:\n",
    "                    y_pred = model_clone.predict(X_v)\n",
    "                    cv_scores.append(accuracy_score(y_v, y_pred))\n",
    "            \n",
    "            return np.mean(cv_scores)\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def optimize_single_run(self, model_type: str, run_idx: int) -> Tuple[Dict, float, GEResult]:\n",
    "        if model_type not in self.MODEL_GRAMMARS:\n",
    "            raise ValueError(f\"Unknown model: {model_type}\")\n",
    "        \n",
    "        grammar = self.MODEL_GRAMMARS[model_type]()\n",
    "        seed = self.config.RANDOM_SEED + run_idx * 1000\n",
    "        \n",
    "        fitness_fn = lambda p: self._fitness_cv(model_type, p, seed_offset=run_idx * 100)\n",
    "        \n",
    "        optimizer = GEOptimizer(\n",
    "            grammar=grammar,\n",
    "            fitness_fn=fitness_fn,\n",
    "            pop_size=self.config.GE_POP_SIZE,\n",
    "            generations=self.config.GE_GENERATIONS_BASELINE,\n",
    "            crossover_rate=self.config.GE_CROSSOVER_RATE,\n",
    "            mutation_rate=self.config.GE_MUTATION_RATE,\n",
    "            tournament_size=self.config.GE_TOURNAMENT_SIZE,\n",
    "            elitism=self.config.GE_ELITISM,\n",
    "            maximize=True,\n",
    "            seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        result = optimizer.evolve()\n",
    "        full_config = {**self.FIXED_PARAMS.get(model_type, {}), **result.best_config}\n",
    "        result.best_config = full_config\n",
    "        return result.best_config, result.best_fitness, result\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CV METRICS COMPUTER\n",
    "# =============================================================================\n",
    "\n",
    "class CVMetricsComputer:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.cv = StratifiedKFold(n_splits=config.CV_FOLDS, shuffle=True, \n",
    "                                  random_state=config.RANDOM_SEED)\n",
    "    \n",
    "    def compute_cv_metrics(self, model, X: np.ndarray, y: np.ndarray,\n",
    "                           use_smote: bool = False) -> Dict[str, Any]:\n",
    "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "        fold_scores = {m: [] for m in metrics}\n",
    "        fold_scores['mcc'] = []\n",
    "        fold_scores['kappa'] = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(self.cv.split(X, y)):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            if use_smote and SMOTE_AVAILABLE:\n",
    "                smote = SMOTE(random_state=self.config.RANDOM_SEED + fold_idx)\n",
    "                X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "            \n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model_clone.predict(X_val)\n",
    "            y_proba = model_clone.predict_proba(X_val)[:, 1] if hasattr(model_clone, 'predict_proba') else None\n",
    "            \n",
    "            fold_scores['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "            fold_scores['precision'].append(precision_score(y_val, y_pred, zero_division=0))\n",
    "            fold_scores['recall'].append(recall_score(y_val, y_pred, zero_division=0))\n",
    "            fold_scores['f1'].append(f1_score(y_val, y_pred, zero_division=0))\n",
    "            fold_scores['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "            fold_scores['kappa'].append(cohen_kappa_score(y_val, y_pred))\n",
    "            \n",
    "            if y_proba is not None:\n",
    "                fold_scores['roc_auc'].append(roc_auc_score(y_val, y_proba))\n",
    "            else:\n",
    "                fold_scores['roc_auc'].append(np.nan)\n",
    "        \n",
    "        summary = {}\n",
    "        for metric, scores in fold_scores.items():\n",
    "            scores_array = np.array([s for s in scores if not np.isnan(s)])\n",
    "            if len(scores_array) > 0:\n",
    "                summary[metric] = compute_statistics(scores_array)\n",
    "            else:\n",
    "                summary[metric] = {'mean': np.nan, 'std': np.nan}\n",
    "        \n",
    "        return {'fold_scores': fold_scores, 'summary': summary, 'n_folds': self.config.CV_FOLDS}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RESULTS PLOTTER\n",
    "# =============================================================================\n",
    "\n",
    "class ResultsPlotter:\n",
    "    def __init__(self, results: Dict, config: Config, output_dir: str = None):\n",
    "        self.results = results\n",
    "        self.config = config\n",
    "        self.output_dir = output_dir or config.RESULTS_DIR\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        self.colors = {\n",
    "            'TabNet': '#2ecc71',\n",
    "            'RandomForest': '#3498db',\n",
    "            'XGBoost': '#e74c3c',\n",
    "            'SVM': '#9b59b6',\n",
    "            'LogisticRegression': '#f39c12',\n",
    "            'GradientBoosting': '#1abc9c'\n",
    "        }\n",
    "    \n",
    "    def _get_color(self, name: str) -> str:\n",
    "        return self.colors.get(name, '#95a5a6')\n",
    "    \n",
    "    def plot_all(self):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Generating Plots\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        self.plot_30runs_comparison()\n",
    "        self.plot_30runs_boxplot()\n",
    "        self.plot_convergence_summary()\n",
    "        self.plot_statistical_tests()\n",
    "        \n",
    "        print(f\"\\nPlots saved to: {self.output_dir}\")\n",
    "    \n",
    "    def plot_30runs_comparison(self):\n",
    "        \"\"\"Bar chart showing mean ± std across 30 runs.\"\"\"\n",
    "        models_data = self.results.get('models', {})\n",
    "        \n",
    "        model_names = []\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for name, data in models_data.items():\n",
    "            if 'runs_summary' in data:\n",
    "                model_names.append(name)\n",
    "                means.append(data['runs_summary']['best_fitness']['mean'])\n",
    "                stds.append(data['runs_summary']['best_fitness']['std'])\n",
    "        \n",
    "        if not model_names:\n",
    "            return\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        colors = [self._get_color(name) for name in model_names]\n",
    "        x = np.arange(len(model_names))\n",
    "        \n",
    "        bars = ax.bar(x, means, yerr=stds, color=colors, edgecolor='black',\n",
    "                     linewidth=1, capsize=5, error_kw={'linewidth': 2})\n",
    "        \n",
    "        for bar, mean, std in zip(bars, means, stds):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.01,\n",
    "                   f'{mean:.4f}\\n±{std:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "        ax.set_ylabel('Best Fitness (AUC)', fontsize=11)\n",
    "        ax.set_title(f'GE Optimization Results ({self.config.N_INDEPENDENT_RUNS} Independent Runs)\\n'\n",
    "                    f'Pop={self.config.GE_POP_SIZE}, Gen={self.config.GE_GENERATIONS}', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if self.config.SAVE_PLOTS:\n",
    "            plt.savefig(os.path.join(self.output_dir, 'comparison_30runs.png'),\n",
    "                       dpi=self.config.PLOT_DPI, bbox_inches='tight')\n",
    "        if self.config.SHOW_PLOTS:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        print(\"Comparison plot saved\")\n",
    "    \n",
    "    def plot_30runs_boxplot(self):\n",
    "        \"\"\"Boxplot showing distribution across 30 runs.\"\"\"\n",
    "        models_data = self.results.get('models', {})\n",
    "        \n",
    "        model_names = []\n",
    "        all_fitness = []\n",
    "        \n",
    "        for name, data in models_data.items():\n",
    "            if 'all_runs' in data:\n",
    "                model_names.append(name)\n",
    "                all_fitness.append([r['best_fitness'] for r in data['all_runs']])\n",
    "        \n",
    "        if not model_names:\n",
    "            return\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        colors = [self._get_color(name) for name in model_names]\n",
    "        \n",
    "        bp = ax.boxplot(all_fitness, labels=model_names, patch_artist=True)\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        \n",
    "        ax.set_ylabel('Best Fitness (AUC)', fontsize=11)\n",
    "        ax.set_title(f'Distribution of Best Fitness ({self.config.N_INDEPENDENT_RUNS} Runs)', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if self.config.SAVE_PLOTS:\n",
    "            plt.savefig(os.path.join(self.output_dir, 'boxplot_30runs.png'),\n",
    "                       dpi=self.config.PLOT_DPI, bbox_inches='tight')\n",
    "        if self.config.SHOW_PLOTS:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        print(\"Boxplot saved\")\n",
    "    \n",
    "    def plot_convergence_summary(self):\n",
    "        \"\"\"Plot mean convergence across 30 runs.\"\"\"\n",
    "        models_data = self.results.get('models', {})\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        for name, data in models_data.items():\n",
    "            if 'convergence_summary' in data:\n",
    "                conv = data['convergence_summary']\n",
    "                generations = range(len(conv['mean']))\n",
    "                mean = np.array(conv['mean'])\n",
    "                std = np.array(conv['std'])\n",
    "                \n",
    "                color = self._get_color(name)\n",
    "                ax.plot(generations, mean, label=name, color=color, linewidth=2)\n",
    "                ax.fill_between(generations, mean - std, mean + std, color=color, alpha=0.2)\n",
    "        \n",
    "        ax.set_xlabel('Generation', fontsize=11)\n",
    "        ax.set_ylabel('Best Fitness (AUC)', fontsize=11)\n",
    "        ax.set_title(f'Mean Convergence ({self.config.N_INDEPENDENT_RUNS} Runs)', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if self.config.SAVE_PLOTS:\n",
    "            plt.savefig(os.path.join(self.output_dir, 'convergence_30runs.png'),\n",
    "                       dpi=self.config.PLOT_DPI, bbox_inches='tight')\n",
    "        if self.config.SHOW_PLOTS:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        print(\"Convergence plot saved\")\n",
    "    \n",
    "    def plot_statistical_tests(self):\n",
    "        \"\"\"Plot statistical test results.\"\"\"\n",
    "        stat_tests = self.results.get('statistical_tests', {})\n",
    "        \n",
    "        if not stat_tests:\n",
    "            return\n",
    "        \n",
    "        models = list(self.results.get('models', {}).keys())\n",
    "        n_models = len(models)\n",
    "        \n",
    "        p_matrix = np.ones((n_models, n_models))\n",
    "        \n",
    "        for key, value in stat_tests.items():\n",
    "            if '_vs_' in key:\n",
    "                parts = key.split('_vs_')\n",
    "                m1, m2 = parts[0], parts[1]\n",
    "                if m1 in models and m2 in models:\n",
    "                    i, j = models.index(m1), models.index(m2)\n",
    "                    p_val = value.get('wilcoxon_p', 1.0)\n",
    "                    if not np.isnan(p_val):\n",
    "                        p_matrix[i, j] = p_val\n",
    "                        p_matrix[j, i] = p_val\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        mask = np.triu(np.ones_like(p_matrix, dtype=bool), k=1)\n",
    "        \n",
    "        sns.heatmap(p_matrix, annot=True, fmt='.4f', cmap='RdYlGn_r',\n",
    "                   xticklabels=models, yticklabels=models, ax=ax,\n",
    "                   mask=mask, vmin=0, vmax=0.1,\n",
    "                   cbar_kws={'label': 'p-value'})\n",
    "        \n",
    "        ax.set_title('Pairwise Wilcoxon Test p-values\\n(Green = Significant Difference)', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if self.config.SAVE_PLOTS:\n",
    "            plt.savefig(os.path.join(self.output_dir, 'statistical_tests.png'),\n",
    "                       dpi=self.config.PLOT_DPI, bbox_inches='tight')\n",
    "        if self.config.SHOW_PLOTS:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        print(\"Statistical tests plot saved\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXPERIMENT\n",
    "# =============================================================================\n",
    "\n",
    "class GEExperiment:\n",
    "    def __init__(self, config: Config = None):\n",
    "        self.config = config or Config()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "        \n",
    "        self.results = {}\n",
    "        \n",
    "        np.random.seed(self.config.RANDOM_SEED)\n",
    "        random.seed(self.config.RANDOM_SEED)\n",
    "        if TABNET_AVAILABLE:\n",
    "            torch.manual_seed(self.config.RANDOM_SEED)\n",
    "    \n",
    "    def load_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Loading Data\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        df = pd.read_csv(self.config.DATA_CSV)\n",
    "        print(f\"Loaded: {df.shape[0]} samples, {df.shape[1]} columns\")\n",
    "        \n",
    "        unnamed_cols = [col for col in df.columns if 'Unnamed' in str(col)]\n",
    "        if unnamed_cols:\n",
    "            df = df.drop(columns=unnamed_cols)\n",
    "        \n",
    "        id_cols = [col for col in df.columns if str(col).lower() == 'id']\n",
    "        if id_cols:\n",
    "            df = df.drop(columns=id_cols)\n",
    "        \n",
    "        target_col = self.config.TARGET_COLUMN\n",
    "        if target_col not in df.columns:\n",
    "            target_col = df.columns[-1]\n",
    "        \n",
    "        print(f\"Target: {target_col}\")\n",
    "        \n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == 'object':\n",
    "                X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "        \n",
    "        if X.isnull().any().any():\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "            X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "        \n",
    "        if y.dtype == 'object':\n",
    "            y = self.label_encoder.fit_transform(y)\n",
    "        else:\n",
    "            y = y.values\n",
    "        \n",
    "        X = X.values.astype(np.float32)\n",
    "        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        print(f\"Features: {X.shape[1]}\")\n",
    "        print(f\"Classes: {np.bincount(y)}\")\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def prepare_splits(self, X: np.ndarray, y: np.ndarray):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Data Splits (80/10/10)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_temp, self.X_test, y_temp, self.y_test = train_test_split(\n",
    "            X, y, test_size=self.config.TEST_SIZE, stratify=y, \n",
    "            random_state=self.config.RANDOM_SEED\n",
    "        )\n",
    "        \n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=self.config.VAL_SIZE, stratify=y_temp,\n",
    "            random_state=self.config.RANDOM_SEED\n",
    "        )\n",
    "        \n",
    "        total = len(y)\n",
    "        print(f\"Train: {len(self.y_train)} ({100*len(self.y_train)/total:.1f}%)\")\n",
    "        print(f\"Val:   {len(self.y_val)} ({100*len(self.y_val)/total:.1f}%)\")\n",
    "        print(f\"Test:  {len(self.y_test)} ({100*len(self.y_test)/total:.1f}%)\")\n",
    "        \n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_val = self.scaler.transform(self.X_val)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "        \n",
    "        self.X_train_val = np.vstack([self.X_train, self.X_val])\n",
    "        self.y_train_val = np.concatenate([self.y_train, self.y_val])\n",
    "    \n",
    "    def run(self) -> Dict:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"GE-BASED HPO - 30 INDEPENDENT RUNS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Population Size: {self.config.GE_POP_SIZE}\")\n",
    "        print(f\"Generations: {self.config.GE_GENERATIONS}\")\n",
    "        print(f\"Independent Runs: {self.config.N_INDEPENDENT_RUNS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        X, y = self.load_data()\n",
    "        self.prepare_splits(X, y)\n",
    "        \n",
    "        results = {\n",
    "            'config': {\n",
    "                'n_independent_runs': self.config.N_INDEPENDENT_RUNS,\n",
    "                'ge_pop_size': self.config.GE_POP_SIZE,\n",
    "                'ge_generations': self.config.GE_GENERATIONS,\n",
    "                'cv_folds': self.config.CV_FOLDS,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            },\n",
    "            'models': {},\n",
    "            'statistical_tests': {}\n",
    "        }\n",
    "        \n",
    "        all_model_fitness = {}\n",
    "        \n",
    "        # TabNet\n",
    "        if TABNET_AVAILABLE:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"TabNet - {self.config.N_INDEPENDENT_RUNS} Independent Runs\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            tabnet_opt = TabNetOptimizer(self.X_train, self.y_train, \n",
    "                                         self.X_val, self.y_val, self.config)\n",
    "            \n",
    "            all_runs = []\n",
    "            all_convergence = []\n",
    "            \n",
    "            for run in range(self.config.N_INDEPENDENT_RUNS):\n",
    "                print(f\"  Run {run+1}/{self.config.N_INDEPENDENT_RUNS}...\", end=\" \")\n",
    "                run_start = time.time()\n",
    "                \n",
    "                try:\n",
    "                    best_config, best_fitness, ge_result = tabnet_opt.optimize_single_run(run)\n",
    "                    \n",
    "                    all_runs.append({\n",
    "                        'run_idx': run,\n",
    "                        'best_config': best_config,\n",
    "                        'best_fitness': best_fitness,\n",
    "                        'generations': ge_result.generations,\n",
    "                        'evaluations': ge_result.evaluations,\n",
    "                        'runtime': ge_result.runtime_seconds\n",
    "                    })\n",
    "                    all_convergence.append(ge_result.history['best_fitness'])\n",
    "                    \n",
    "                    print(f\"AUC={best_fitness:.4f}, Time={time.time()-run_start:.1f}s\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    all_runs.append({'run_idx': run, 'best_fitness': 0, 'error': str(e)})\n",
    "            \n",
    "            fitness_values = np.array([r['best_fitness'] for r in all_runs if 'error' not in r])\n",
    "            all_model_fitness['TabNet'] = fitness_values\n",
    "            \n",
    "            # Compute convergence summary\n",
    "            max_gen = max(len(c) for c in all_convergence) if all_convergence else 0\n",
    "            padded = [c + [c[-1]]*(max_gen-len(c)) if len(c) < max_gen else c for c in all_convergence]\n",
    "            conv_array = np.array(padded)\n",
    "            \n",
    "            results['models']['TabNet'] = {\n",
    "                'all_runs': all_runs,\n",
    "                'runs_summary': {\n",
    "                    'best_fitness': compute_statistics(fitness_values),\n",
    "                    'n_successful_runs': len(fitness_values)\n",
    "                },\n",
    "                'convergence_summary': {\n",
    "                    'mean': conv_array.mean(axis=0).tolist(),\n",
    "                    'std': conv_array.std(axis=0).tolist()\n",
    "                },\n",
    "                'best_overall': all_runs[np.argmax([r['best_fitness'] for r in all_runs if 'error' not in r])]\n",
    "            }\n",
    "            \n",
    "            print(f\"\\nTabNet Summary: {fitness_values.mean():.4f} ± {fitness_values.std():.4f}\")\n",
    "        \n",
    "        # Baseline models\n",
    "        baseline_models = ['RandomForest', 'LogisticRegression', 'SVM', 'GradientBoosting']\n",
    "        if XGBOOST_AVAILABLE:\n",
    "            baseline_models.append('XGBoost')\n",
    "        \n",
    "        baseline_opt = BaselineOptimizer(self.X_train, self.y_train,\n",
    "                                         self.X_val, self.y_val, self.config)\n",
    "        \n",
    "        for model_name in baseline_models:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"{model_name} - {self.config.N_INDEPENDENT_RUNS} Independent Runs\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            all_runs = []\n",
    "            all_convergence = []\n",
    "            \n",
    "            for run in range(self.config.N_INDEPENDENT_RUNS):\n",
    "                print(f\"  Run {run+1}/{self.config.N_INDEPENDENT_RUNS}...\", end=\" \")\n",
    "                run_start = time.time()\n",
    "                \n",
    "                try:\n",
    "                    best_config, best_fitness, ge_result = baseline_opt.optimize_single_run(model_name, run)\n",
    "                    \n",
    "                    all_runs.append({\n",
    "                        'run_idx': run,\n",
    "                        'best_config': best_config,\n",
    "                        'best_fitness': best_fitness,\n",
    "                        'generations': ge_result.generations,\n",
    "                        'evaluations': ge_result.evaluations,\n",
    "                        'runtime': ge_result.runtime_seconds\n",
    "                    })\n",
    "                    all_convergence.append(ge_result.history['best_fitness'])\n",
    "                    \n",
    "                    print(f\"AUC={best_fitness:.4f}, Time={time.time()-run_start:.1f}s\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    all_runs.append({'run_idx': run, 'best_fitness': 0, 'error': str(e)})\n",
    "            \n",
    "            fitness_values = np.array([r['best_fitness'] for r in all_runs if 'error' not in r])\n",
    "            all_model_fitness[model_name] = fitness_values\n",
    "            \n",
    "            max_gen = max(len(c) for c in all_convergence) if all_convergence else 0\n",
    "            padded = [c + [c[-1]]*(max_gen-len(c)) if len(c) < max_gen else c for c in all_convergence]\n",
    "            conv_array = np.array(padded) if padded else np.array([[]])\n",
    "            \n",
    "            results['models'][model_name] = {\n",
    "                'all_runs': all_runs,\n",
    "                'runs_summary': {\n",
    "                    'best_fitness': compute_statistics(fitness_values),\n",
    "                    'n_successful_runs': len(fitness_values)\n",
    "                },\n",
    "                'convergence_summary': {\n",
    "                    'mean': conv_array.mean(axis=0).tolist() if conv_array.size > 0 else [],\n",
    "                    'std': conv_array.std(axis=0).tolist() if conv_array.size > 0 else []\n",
    "                },\n",
    "                'best_overall': all_runs[np.argmax([r['best_fitness'] for r in all_runs if 'error' not in r])] if any('error' not in r for r in all_runs) else None\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{model_name} Summary: {fitness_values.mean():.4f} ± {fitness_values.std():.4f}\")\n",
    "        \n",
    "        # Statistical tests\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Statistical Tests\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        model_names = list(all_model_fitness.keys())\n",
    "        for i in range(len(model_names)):\n",
    "            for j in range(i+1, len(model_names)):\n",
    "                m1, m2 = model_names[i], model_names[j]\n",
    "                scores1, scores2 = all_model_fitness[m1], all_model_fitness[m2]\n",
    "                \n",
    "                if len(scores1) == len(scores2) and len(scores1) > 0:\n",
    "                    t_stat, t_p = paired_ttest(scores1, scores2)\n",
    "                    w_stat, w_p = wilcoxon_test(scores1, scores2)\n",
    "                    \n",
    "                    results['statistical_tests'][f'{m1}_vs_{m2}'] = {\n",
    "                        'ttest_statistic': t_stat,\n",
    "                        'ttest_p': t_p,\n",
    "                        'wilcoxon_statistic': w_stat,\n",
    "                        'wilcoxon_p': w_p,\n",
    "                        'mean_diff': float(scores1.mean() - scores2.mean())\n",
    "                    }\n",
    "                    \n",
    "                    sig = \"***\" if w_p < 0.001 else \"**\" if w_p < 0.01 else \"*\" if w_p < 0.05 else \"\"\n",
    "                    print(f\"  {m1} vs {m2}: p={w_p:.4f} {sig}\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        results['total_runtime_seconds'] = total_time\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"EXPERIMENT COMPLETE\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total Runtime: {total_time:.1f}s ({total_time/60:.1f} min)\")\n",
    "        print(f\"\\nResults Summary ({self.config.N_INDEPENDENT_RUNS} runs each):\")\n",
    "        \n",
    "        for name, data in results['models'].items():\n",
    "            if 'runs_summary' in data:\n",
    "                stats = data['runs_summary']['best_fitness']\n",
    "                print(f\"  {name}: {stats['mean']:.4f} ± {stats['std']:.4f} \"\n",
    "                      f\"[{stats['min']:.4f}, {stats['max']:.4f}]\")\n",
    "        \n",
    "        # Save results\n",
    "        os.makedirs(self.config.RESULTS_DIR, exist_ok=True)\n",
    "        results_file = os.path.join(\n",
    "            self.config.RESULTS_DIR,\n",
    "            f\"ge_30runs_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        )\n",
    "        \n",
    "        def convert(obj):\n",
    "            if isinstance(obj, np.integer): return int(obj)\n",
    "            elif isinstance(obj, np.floating): return float(obj)\n",
    "            elif isinstance(obj, np.ndarray): return obj.tolist()\n",
    "            return obj\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=convert)\n",
    "        print(f\"\\nResults saved: {results_file}\")\n",
    "        \n",
    "        self.results = results\n",
    "        \n",
    "        # Generate plots\n",
    "        plotter = ResultsPlotter(results, self.config)\n",
    "        plotter.plot_all()\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def run_experiment():\n",
    "    config = Config()\n",
    "    experiment = GEExperiment(config)\n",
    "    return experiment.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GE-based HPO - 30 Independent Runs Version\")\n",
    "    print(\"=\" * 60)\n",
    "    results = run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
