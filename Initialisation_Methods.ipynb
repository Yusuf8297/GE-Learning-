{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c74214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " GE INITIALIZATION COMPARISON — BDS/GRAPE Setup\n",
      "======================================================================\n",
      " Date: 2026-02-11 19:10\n",
      " Pop=200 Gens=200 Tourn=7 CX=0.8 Mut=0.01\n",
      " Random genome=[30,50]  Sensible depth=[3,13]\n",
      " MaxTreeDepth=35 CodonSize=255 Lazy mapper\n",
      " Fitness=MSE  N_RUNS=30\n",
      "\n",
      ">>> Pagie-1: 1/(1+x^-4)+1/(1+y^-4), 2D grid\n",
      "    Grammar: 2 NTs, 21 total productions\n",
      "      <e>: 11 prods (recursive=8, non-recursive=3)\n",
      "      <c>: 10 prods (recursive=0, non-recursive=10)\n",
      "    Random run 1/30...\n",
      "    Random run 5/30...\n",
      "    Random run 10/30...\n",
      "    Random run 15/30...\n",
      "    Random run 20/30...\n",
      "    Random run 25/30...\n",
      "    Random run 30/30...\n",
      "    Random: 580s (19.3s/run)\n",
      "    Sensible run 1/30...\n",
      "    Sensible run 5/30...\n",
      "    Sensible run 10/30...\n",
      "    Sensible run 15/30...\n",
      "    Sensible run 20/30...\n",
      "    Sensible run 25/30...\n",
      "    Sensible run 30/30...\n",
      "    Sensible: 903s (30.1s/run)\n",
      "\n",
      ">>> Vladislavleva-4: 10/(5+sum(xi-3)^2), 5D\n",
      "    Grammar: 2 NTs, 25 total productions\n",
      "      <e>: 15 prods (recursive=9, non-recursive=6)\n",
      "      <c>: 10 prods (recursive=0, non-recursive=10)\n",
      "    Random run 1/30...\n",
      "    Random run 5/30...\n",
      "    Random run 10/30...\n",
      "    Random run 15/30...\n",
      "    Random run 20/30...\n",
      "    Random run 25/30...\n",
      "    Random run 30/30...\n",
      "    Random: 563s (18.8s/run)\n",
      "    Sensible run 1/30...\n",
      "    Sensible run 5/30...\n",
      "    Sensible run 10/30...\n",
      "    Sensible run 15/30...\n",
      "    Sensible run 20/30...\n",
      "    Sensible run 25/30...\n",
      "    Sensible run 30/30...\n",
      "    Sensible: 616s (20.5s/run)\n",
      "\n",
      "TOTAL: 44.4 min\n",
      "\n",
      "======================================================================\n",
      " Pagie-1\n",
      "======================================================================\n",
      "  Init Validity %       : Rand=   66.6167+-3.7164    Sens=  100.0000+-0.0000    p=0.0000(***) A=1.000(large)\n",
      "  Init Unique Pheno     : Rand=   93.3333+-6.7594    Sens=  179.7000+-3.4559    p=0.0000(***) A=1.000(large)\n",
      "  Init Mean Depth       : Rand=    4.4968+-0.1881    Sens=    9.1373+-0.1065    p=0.0000(***) A=1.000(large)\n",
      "  Init Mean Nodes       : Rand=    3.9318+-0.2924    Sens=   47.6552+-2.6429    p=0.0000(***) A=1.000(large)\n",
      "  Init Mean GenomeLen   : Rand=   40.1101+-0.5270    Sens=  208.5825+-11.4712   p=0.0000(***) A=1.000(large)\n",
      "  Init Struct Diversity : Rand=    0.7005+-0.0308    Sens=    0.8985+-0.0173    p=0.0000(***) A=1.000(large)\n",
      "  Init Best MSE         : Rand=    0.1894+-0.0152    Sens=    0.1846+-0.0320    p=0.3457(ns) A=0.446(negl)\n",
      "  Init Mean MSE         : insufficient data\n",
      "  Final Train MSE       : Rand=    0.0316+-0.0278    Sens=    0.0236+-0.0211    p=0.0467(*) A=0.350(medium)\n",
      "  Final Test MSE        : Rand=    0.0410+-0.0320    Sens=    0.0316+-0.0215    p=0.2170(ns) A=0.407(small)\n",
      "\n",
      "  Best solutions found:\n",
      "    Random: Train MSE=0.007244  Test MSE=0.013622  Depth=35  Nodes=31\n",
      "      np.sin(plog(x[0]))+np.tanh(psqrt(x[1]*plog(x[0]*np.tanh(x[1]*x[1]*np.tanh(x[1]*psqrt(x[1]))*x[1]*np.sin(x[1]*np.sin(np.t\n",
      "    Sensible: Train MSE=0.007513  Test MSE=0.013166  Depth=28  Nodes=24\n",
      "      np.tanh(psqrt(x[1])*psqrt(plog(x[0])*np.tanh(plog(x[1])*x[1]*x[1]*psqrt(x[1])*plog(psqrt(psqrt(x[1])))*psqrt(np.tanh(plo\n",
      "\n",
      "======================================================================\n",
      " Vladislavleva-4\n",
      "======================================================================\n",
      "  Init Validity %       : Rand=   93.6000+-1.9035    Sens=   93.7333+-1.7923    p=0.9822(ns) A=0.502(negl)\n",
      "  Init Unique Pheno     : Rand=  119.4667+-6.4845    Sens=  156.8667+-4.9378    p=0.0000(***) A=1.000(large)\n",
      "  Init Mean Depth       : Rand=    4.2434+-0.2121    Sens=    8.2308+-0.1429    p=0.0000(***) A=1.000(large)\n",
      "  Init Mean Nodes       : Rand=    3.0455+-0.2080    Sens=   26.7874+-1.9577    p=0.0000(***) A=1.000(large)\n",
      "  Init Mean GenomeLen   : Rand=   40.0432+-0.4150    Sens=  126.5482+-8.8741    p=0.0000(***) A=1.000(large)\n",
      "  Init Struct Diversity : Rand=    0.6382+-0.0330    Sens=    0.8368+-0.0227    p=0.0000(***) A=1.000(large)\n",
      "  Init Best MSE         : Rand=    0.0476+-0.0090    Sens=    0.0432+-0.0057    p=0.0773(ns) A=0.367(small)\n",
      "  Init Mean MSE         : insufficient data\n",
      "  Final Train MSE       : Rand=    0.0291+-0.0056    Sens=    0.0251+-0.0084    p=0.0891(ns) A=0.372(small)\n",
      "  Final Test MSE        : Rand=    0.0308+-0.0054    Sens=    0.0272+-0.0081    p=0.0919(ns) A=0.373(small)\n",
      "\n",
      "  Best solutions found:\n",
      "    Random: Train MSE=0.011964  Test MSE=0.016998  Depth=23  Nodes=14\n",
      "      np.sin(plog(np.sin(psqrt(x[2]))*psqrt(exp(np.tanh(exp(np.sin(np.sin(np.sin(psqrt(exp(psqrt(np.sin(psqrt(x[1]))))))))))))\n",
      "    Sensible: Train MSE=0.008259  Test MSE=0.010984  Depth=33  Nodes=34\n",
      "      plog(psqrt(psqrt(np.sin(psqrt(x[0]))*np.sin(psqrt(x[1]))*np.sin(psqrt(psqrt(psqrt(x[2]))))*exp(np.sin(psqrt(psqrt(psqrt(\n",
      "\n",
      "Saved: fig1_initial_quality.png\n",
      "Saved: fig2_convergence.png\n",
      "Saved: fig3_boxplots.png\n",
      "Saved: fig4_structure.png\n",
      "Saved: fig5_invalids.png\n",
      "\n",
      "======================================================================\n",
      " ALL DONE — 44.4 min total\n",
      "======================================================================\n",
      " Output files:\n",
      "   fig1_initial_quality.png\n",
      "   fig2_convergence.png\n",
      "   fig3_boxplots.png\n",
      "   fig4_structure.png\n",
      "   fig5_invalids.png\n",
      "   ge_results_raw.json\n",
      "   experiment_config.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "==========================================================================\n",
    " GRAMMATICAL EVOLUTION: INITIALIZATION METHODS COMPARISON\n",
    "==========================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import mannwhitneyu\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# ==========================================================================\n",
    "#  1. PROTECTED FUNCTIONS — exact copies from GRAPE functions.py\n",
    "# ==========================================================================\n",
    "\n",
    "def pdiv(a, b):\n",
    "    \"\"\"Protected division (GRAPE functions.py line 32).\"\"\"\n",
    "    try:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            return np.where(b == 0, np.ones_like(a), a / b)\n",
    "    except ZeroDivisionError:\n",
    "        return 1.0\n",
    "\n",
    "def plog(a):\n",
    "    \"\"\"Protected log: log(1+|a|) (GRAPE functions.py line 66).\"\"\"\n",
    "    return np.log(1.0 + np.abs(a))\n",
    "\n",
    "def psqrt(a):\n",
    "    \"\"\"Protected sqrt: sqrt(|a|) (GRAPE functions.py line 56).\"\"\"\n",
    "    return np.sqrt(abs(a))\n",
    "\n",
    "def exp(a):\n",
    "    \"\"\"Exponential with overflow protection.\"\"\"\n",
    "    return np.exp(np.clip(a, -500, 500))\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  2. GRAMMAR — reproducing GRAPE's Grammar class\n",
    "#     (grape.py)\n",
    "# ==========================================================================\n",
    "\n",
    "class Grammar:\n",
    "    \"\"\"\n",
    "    Faithful reproduction of GRAPE's Grammar class.\n",
    "    Parses BNF, classifies recursive/non-recursive rules,\n",
    "    computes minimum depths to terminate mapping.\n",
    "    \n",
    "    Each production rule is stored as:\n",
    "      [0] string, [1] 'terminal'/'non-terminal', [2] arity,\n",
    "      [3] production choice label, [4] recursive (bool),\n",
    "      [5] min depth to terminate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bnf_text):\n",
    "        bnf_grammar = re.sub(r\"\\s+\", \" \", bnf_text)\n",
    "\n",
    "        # Extract non-terminals\n",
    "        self.non_terminals = [\n",
    "            '<' + t + '>'\n",
    "            for t in re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\\s*::=\", bnf_grammar)\n",
    "        ]\n",
    "        self.start_rule = self.non_terminals[0]\n",
    "\n",
    "        # Strip NT definitions, split by ::=\n",
    "        for nt in self.non_terminals:\n",
    "            bnf_grammar = bnf_grammar.replace(nt + \" ::=\", \"  ::=\")\n",
    "        rules = bnf_grammar.split(\"::=\")[1:]\n",
    "        rules = [r.replace('\\n', '').replace('\\t', '') for r in rules]\n",
    "\n",
    "        # Parse production rules\n",
    "        self.production_rules = [r.split('|') for r in rules]\n",
    "        for i in range(len(self.production_rules)):\n",
    "            self.production_rules[i] = [\n",
    "                p.strip() for p in self.production_rules[i]\n",
    "            ]\n",
    "            for j in range(len(self.production_rules[i])):\n",
    "                pr_str = self.production_rules[i][j]\n",
    "                nts_in = re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", pr_str)\n",
    "                if nts_in:\n",
    "                    self.production_rules[i][j] = [\n",
    "                        pr_str, \"non-terminal\", len(nts_in), j\n",
    "                    ]\n",
    "                else:\n",
    "                    self.production_rules[i][j] = [\n",
    "                        pr_str, \"terminal\", 0, j\n",
    "                    ]\n",
    "\n",
    "        self.n_rules = [len(lst) for lst in self.production_rules]\n",
    "\n",
    "        # --- Recursiveness check (exact GRAPE logic) ---\n",
    "        for i in range(len(self.production_rules)):\n",
    "            for j in range(len(self.production_rules[i])):\n",
    "                nts = [\n",
    "                    '<' + t + '>'\n",
    "                    for t in re.findall(\n",
    "                        r\"\\<([\\(\\)\\w,\\-.]+)\\>\",\n",
    "                        self.production_rules[i][j][0]\n",
    "                    )\n",
    "                ]\n",
    "                recursive = False\n",
    "                for nt_c in list(dict.fromkeys(nts)):\n",
    "                    stack = [self.non_terminals[i]]\n",
    "                    if nt_c in stack:\n",
    "                        recursive = True\n",
    "                        break\n",
    "                    stack.append(nt_c)\n",
    "                    recursive = self._check_rec(nt_c, stack)\n",
    "                    if recursive:\n",
    "                        break\n",
    "                    stack.pop()\n",
    "                self.production_rules[i][j].append(recursive)  # index [4]\n",
    "\n",
    "        # --- Minimum depth to terminate (GRAPE logic) ---\n",
    "        nt_depth = [None] * len(self.non_terminals)\n",
    "        part_depth = []\n",
    "        isolated_nt = []\n",
    "        for i in range(len(self.production_rules)):\n",
    "            part_depth.append([])\n",
    "            isolated_nt.append([])\n",
    "            for j in range(len(self.production_rules[i])):\n",
    "                part_depth[i].append([])\n",
    "                isolated_nt[i].append([])\n",
    "                if self.production_rules[i][j][1] == 'terminal':\n",
    "                    isolated_nt[i][j].append(None)\n",
    "                    part_depth[i][j] = 1\n",
    "                    if not nt_depth[i]:\n",
    "                        nt_depth[i] = 1\n",
    "                else:\n",
    "                    for k in range(self.production_rules[i][j][2]):\n",
    "                        part_depth[i][j].append([])\n",
    "                        t = re.findall(\n",
    "                            r\"\\<([\\(\\)\\w,\\-.]+)\\>\",\n",
    "                            self.production_rules[i][j][0]\n",
    "                        )[k]\n",
    "                        isolated_nt[i][j].append('<' + t + '>')\n",
    "\n",
    "        cont = True\n",
    "        while cont:\n",
    "            if None not in nt_depth:\n",
    "                cont = False\n",
    "            for i in range(len(self.non_terminals)):\n",
    "                for j in range(len(self.production_rules)):\n",
    "                    for k in range(len(self.production_rules[j])):\n",
    "                        for l in range(len(isolated_nt[j][k])):\n",
    "                            if self.non_terminals[i] == isolated_nt[j][k][l]:\n",
    "                                if nt_depth[i] and not part_depth[j][k][l]:\n",
    "                                    part_depth[j][k][l] = nt_depth[i] + 1\n",
    "                                    if ([] not in part_depth[j][k]\n",
    "                                            and not nt_depth[j]):\n",
    "                                        nt_depth[j] = part_depth[j][k][l]\n",
    "\n",
    "        for i in range(len(part_depth)):\n",
    "            for j in range(len(part_depth[i])):\n",
    "                d = (part_depth[i][j]\n",
    "                     if isinstance(part_depth[i][j], int)\n",
    "                     else max(part_depth[i][j]))\n",
    "                self.production_rules[i][j].append(d)  # index [5]\n",
    "\n",
    "    def _check_rec(self, nt, stack):\n",
    "        \"\"\"Exact reproduction of GRAPE's check_recursiveness().\"\"\"\n",
    "        idx = self.non_terminals.index(nt)\n",
    "        for j in range(len(self.production_rules[idx])):\n",
    "            nts = [\n",
    "                '<' + t + '>'\n",
    "                for t in re.findall(\n",
    "                    r\"\\<([\\(\\)\\w,\\-.]+)\\>\",\n",
    "                    self.production_rules[idx][j][0]\n",
    "                )\n",
    "            ]\n",
    "            for nc in list(dict.fromkeys(nts)):\n",
    "                if nc in stack:\n",
    "                    return True\n",
    "                stack.append(nc)\n",
    "                if self._check_rec(nc, stack):\n",
    "                    return True\n",
    "                stack.pop()\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  3. MAPPER — lazy codon consumption (GRAPE default)\n",
    "#     (grape.py)\n",
    "# ==========================================================================\n",
    "\n",
    "def mapper_lazy(genome, grammar, max_depth):\n",
    "    \"\"\"\n",
    "    Lazy mapper: only consumes a codon when there are >1 production choices\n",
    "    for the current non-terminal. This is the GRAPE default.\n",
    "    \"\"\"\n",
    "    idx_genome = 0\n",
    "    phenotype = grammar.start_rule\n",
    "    nxt = re.search(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "    if not nxt:\n",
    "        return phenotype, 0, 1, 0, True, 0, []\n",
    "\n",
    "    next_NT = nxt.group()\n",
    "    n_start = len(re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype))\n",
    "    list_depth = [1] * n_start\n",
    "    idx_depth = 0\n",
    "    nodes = 0\n",
    "    structure = []\n",
    "\n",
    "    while next_NT and idx_genome < len(genome):\n",
    "        NT_i = grammar.non_terminals.index(next_NT)\n",
    "        n_opts = grammar.n_rules[NT_i]\n",
    "\n",
    "        if n_opts > 1:\n",
    "            idx_prod = genome[idx_genome] % n_opts\n",
    "            idx_genome += 1\n",
    "        else:\n",
    "            idx_prod = 0\n",
    "\n",
    "        pr = grammar.production_rules[NT_i][idx_prod]\n",
    "        structure.append(pr[3])\n",
    "        phenotype = phenotype.replace(next_NT, pr[0], 1)\n",
    "        list_depth[idx_depth] += 1\n",
    "\n",
    "        if list_depth[idx_depth] > max_depth:\n",
    "            break\n",
    "\n",
    "        if pr[2] == 0:  # terminal\n",
    "            idx_depth += 1\n",
    "            nodes += 1\n",
    "        elif pr[2] > 1:  # arity > 1\n",
    "            ar = pr[2]\n",
    "            if idx_depth == 0:\n",
    "                list_depth = [list_depth[0]] * ar + list_depth[1:]\n",
    "            else:\n",
    "                list_depth = (list_depth[:idx_depth]\n",
    "                              + [list_depth[idx_depth]] * ar\n",
    "                              + list_depth[idx_depth + 1:])\n",
    "\n",
    "        nxt = re.search(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "        next_NT = nxt.group() if nxt else None\n",
    "\n",
    "    if next_NT:\n",
    "        return phenotype, nodes, max(list_depth), 0, True, 0, structure\n",
    "    return phenotype, nodes, max(list_depth), idx_genome, False, 0, structure\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  4. INDIVIDUAL\n",
    "# ==========================================================================\n",
    "\n",
    "class Individual:\n",
    "    \"\"\"GE individual with genome-to-phenotype mapping.\"\"\"\n",
    "    __slots__ = [\n",
    "        'genome', 'phenotype', 'nodes', 'depth',\n",
    "        'used_codons', 'invalid', 'n_wraps', 'structure', 'fitness'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, genome, grammar, max_depth):\n",
    "        self.genome = genome\n",
    "        (self.phenotype, self.nodes, self.depth,\n",
    "         self.used_codons, self.invalid, self.n_wraps,\n",
    "         self.structure) = mapper_lazy(genome, grammar, max_depth)\n",
    "        self.fitness = None\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  5. INITIALISATION — exact GRAPE logic\n",
    "#     (grape.py)\n",
    "# ==========================================================================\n",
    "\n",
    "def random_initialisation(pop_size, grammar, min_gl, max_gl,\n",
    "                          max_depth, codon_size):\n",
    "    \"\"\"\n",
    "    Random initialisation: genome of random length [min_gl, max_gl]\n",
    "    with random integer codons in [0, codon_size].\n",
    "    (GRAPE grape.py)\n",
    "    \"\"\"\n",
    "    pop = []\n",
    "    for _ in range(pop_size):\n",
    "        gl = random.randint(min_gl, max_gl)\n",
    "        genome = [random.randint(0, codon_size) for _ in range(gl)]\n",
    "        pop.append(Individual(genome, grammar, max_depth))\n",
    "    return pop\n",
    "\n",
    "\n",
    "def sensible_initialisation(pop_size, grammar, min_d, max_d, codon_size):\n",
    "    \"\"\"\n",
    "    Sensible initialisation with Ramped Half-and-Half (RHH).\n",
    "    Half Grow (ramped across depths), half Full.\n",
    "    (GRAPE grape.py)\n",
    "    \"\"\"\n",
    "    is_odd = pop_size % 2\n",
    "    n_grow = pop_size // 2\n",
    "    n_sets = max_d - min_d + 1\n",
    "    set_sz = n_grow // n_sets\n",
    "    remaining = n_grow % n_sets\n",
    "    n_full = n_grow + is_odd + remaining\n",
    "\n",
    "    pop = []\n",
    "\n",
    "    # Grow (ramped)\n",
    "    for i in range(n_sets):\n",
    "        md = min_d + i\n",
    "        for _ in range(set_sz):\n",
    "            pop.append(_build_tree(grammar, md, codon_size, 'grow'))\n",
    "\n",
    "    # Full\n",
    "    for _ in range(n_full):\n",
    "        pop.append(_build_tree(grammar, max_d, codon_size, 'full'))\n",
    "\n",
    "    return pop\n",
    "\n",
    "\n",
    "def _build_tree(grammar, max_depth, codon_size, method):\n",
    "    \"\"\"Build one individual using grow or full method (GRAPE style).\"\"\"\n",
    "    remainders = []\n",
    "    possible_choices = []\n",
    "\n",
    "    phenotype = grammar.start_rule\n",
    "    rem_NTs = [\n",
    "        '<' + t + '>'\n",
    "        for t in re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "    ]\n",
    "    depths = [1] * len(rem_NTs)\n",
    "    idx_b = 0\n",
    "\n",
    "    while rem_NTs:\n",
    "        idx_NT = grammar.non_terminals.index(rem_NTs[0])\n",
    "        total = grammar.production_rules[idx_NT]\n",
    "        actual = [pr for pr in total\n",
    "                  if pr[5] + depths[idx_b] <= max_depth]\n",
    "\n",
    "        if not actual:\n",
    "            # Fallback: try terminals, then all options\n",
    "            actual = [pr for pr in total if pr[1] == 'terminal']\n",
    "            if not actual:\n",
    "                actual = total\n",
    "\n",
    "        if method == 'full':\n",
    "            # Full: prefer recursive options to build deeper trees\n",
    "            rec = [pr for pr in actual if pr[4]]\n",
    "            ch = random.choice(rec) if rec else random.choice(actual)\n",
    "        else:\n",
    "            # Grow: choose uniformly from all valid options\n",
    "            ch = random.choice(actual)\n",
    "\n",
    "        phenotype = phenotype.replace(rem_NTs[0], ch[0], 1)\n",
    "        depths[idx_b] += 1\n",
    "\n",
    "        # Lazy codon consumption\n",
    "        if len(total) > 1:\n",
    "            remainders.append(ch[3])\n",
    "            possible_choices.append(len(total))\n",
    "\n",
    "        if ch[2] > 1:  # arity > 1\n",
    "            ar = ch[2]\n",
    "            if idx_b == 0:\n",
    "                depths = [depths[0]] * ar + depths[1:]\n",
    "            else:\n",
    "                depths = (depths[:idx_b]\n",
    "                          + [depths[idx_b]] * ar\n",
    "                          + depths[idx_b + 1:])\n",
    "\n",
    "        if ch[1] == 'terminal':\n",
    "            idx_b += 1\n",
    "\n",
    "        rem_NTs = [\n",
    "            '<' + t + '>'\n",
    "            for t in re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "        ]\n",
    "\n",
    "    # Generate genome from chosen remainders (exact GRAPE codon formula)\n",
    "    genome = []\n",
    "    for k in range(len(remainders)):\n",
    "        codon = (\n",
    "            random.randint(0, int(1e10))\n",
    "            % math.floor((codon_size + 1) / possible_choices[k])\n",
    "            * possible_choices[k]\n",
    "        ) + remainders[k]\n",
    "        genome.append(codon)\n",
    "\n",
    "    # Tail = 50% of genome length (GRAPE grape.py line 474-477)\n",
    "    tail = max(int(0.5 * len(genome)), 1)\n",
    "    for _ in range(tail):\n",
    "        genome.append(random.randint(0, codon_size))\n",
    "\n",
    "    return Individual(genome, grammar, max_depth)\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  6. GENETIC OPERATORS\n",
    "# ==========================================================================\n",
    "\n",
    "def crossover_onepoint(p0, p1, grammar, max_depth):\n",
    "    \"\"\"One-point crossover within the effective genome (GRAPE style).\"\"\"\n",
    "    cx0 = max(1, min(len(p0.genome), p0.used_codons)\n",
    "              if not p0.invalid else len(p0.genome))\n",
    "    cx1 = max(1, min(len(p1.genome), p1.used_codons)\n",
    "              if not p1.invalid else len(p1.genome))\n",
    "\n",
    "    for _ in range(20):  # retry if depth violated\n",
    "        pt0 = random.randint(1, cx0)\n",
    "        pt1 = random.randint(1, cx1)\n",
    "        g0 = p0.genome[:pt0] + p1.genome[pt1:]\n",
    "        g1 = p1.genome[:pt1] + p0.genome[pt0:]\n",
    "        c0 = Individual(g0, grammar, max_depth)\n",
    "        c1 = Individual(g1, grammar, max_depth)\n",
    "        if c0.depth <= max_depth and c1.depth <= max_depth:\n",
    "            return c0, c1\n",
    "\n",
    "    # Fallback: return clones\n",
    "    return (Individual(p0.genome[:], grammar, max_depth),\n",
    "            Individual(p1.genome[:], grammar, max_depth))\n",
    "\n",
    "\n",
    "def mutation_int_flip(ind, mut_pb, codon_size, grammar, max_depth):\n",
    "    \"\"\"Per-codon integer flip mutation (GRAPE style).\"\"\"\n",
    "    g = ind.genome[:]\n",
    "    for i in range(len(g)):\n",
    "        if random.random() < mut_pb:\n",
    "            g[i] = random.randint(0, codon_size)\n",
    "    return Individual(g, grammar, max_depth)\n",
    "\n",
    "\n",
    "def tournament_sel(pop, k, ts):\n",
    "    \"\"\"Standard tournament selection.\"\"\"\n",
    "    sel = []\n",
    "    for _ in range(k):\n",
    "        asp = random.sample(pop, min(ts, len(pop)))\n",
    "        sel.append(min(\n",
    "            asp,\n",
    "            key=lambda x: (x.fitness\n",
    "                           if x.fitness is not None and not np.isnan(x.fitness)\n",
    "                           else float('inf'))\n",
    "        ))\n",
    "    return sel\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  7. PARAMETERS — \n",
    "# ==========================================================================\n",
    "\n",
    "POP_SIZE       = 200   \n",
    "MAX_GENS       = 200   \n",
    "P_CX           = 0.8   \n",
    "P_MUT          = 0.01  \n",
    "ELITE          = 0     \n",
    "TOURN          = 7     \n",
    "\n",
    "MIN_INIT_GL    = 30    # Random init genome length \n",
    "MAX_INIT_GL    = 50    # Random init genome length\n",
    "\n",
    "MAX_INIT_DEPTH = 13    # Sensible init max depth \n",
    "MIN_INIT_DEPTH = 3     # Sensible init min depth \n",
    "MAX_TREE_DEPTH = 35    # Runtime depth limit \n",
    "CODON_SIZE     = 255   # GRAPE line \n",
    "\n",
    "N_RUNS         = 30    # Standard for statistical comparison\n",
    "\n",
    "COLORS = {'Random': '#E74C3C', 'Sensible': '#3498DB'}\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  8. GRAMMARS \n",
    "# ==========================================================================\n",
    "\n",
    "PAGIE1_BNF = (\n",
    "    \"<e> ::= <e>+<e> | <e>-<e> | <e>*<e> | pdiv(<e>,<e>) | \"\n",
    "    \"psqrt(<e>) | np.sin(<e>) | np.tanh(<e>) | plog(<e>) | \"\n",
    "    \"x[0] | x[1] | <c><c>.<c><c>\\n\"\n",
    "    \"<c> ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\"\n",
    ")\n",
    "\n",
    "VLAD4_BNF = (\n",
    "    \"<e> ::= <e>+<e> | <e>-<e> | <e>*<e> | pdiv(<e>,<e>) | \"\n",
    "    \"psqrt(<e>) | np.sin(<e>) | np.tanh(<e>) | exp(<e>) | plog(<e>) | \"\n",
    "    \"x[0] | x[1] | x[2] | x[3] | x[4] | <c><c>.<c><c>\\n\"\n",
    "    \"<c> ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\"\n",
    ")\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  9. DATASETS \n",
    "# ==========================================================================\n",
    "\n",
    "def load_pagie1(seed):\n",
    "    \"\"\"\n",
    "    Pagie-1: 1/(1+x^-4) + 1/(1+y^-4)\n",
    "    Training: 26×26 grid on [-5, 5] = 676 points (GRAPE exact)\n",
    "    Test: 10,000 uniform random points\n",
    "    \"\"\"\n",
    "    vals = np.linspace(-5, 5, 26)  # 26 values, step ~0.4\n",
    "    X0, X1 = np.meshgrid(vals, vals)\n",
    "    x0, x1 = X0.ravel(), X1.ravel()\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        y = (1.0 / (1.0 + np.power(np.abs(x0) + 1e-10, -4))\n",
    "             + 1.0 / (1.0 + np.power(np.abs(x1) + 1e-10, -4)))\n",
    "    y = np.nan_to_num(y, nan=0.0, posinf=2.0, neginf=0.0)\n",
    "    X_tr = np.array([x0, x1])  # shape (2, 676) — GRAPE format\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    x0t = rng.uniform(-5, 5, 10000)\n",
    "    x1t = rng.uniform(-5, 5, 10000)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        yt = (1.0 / (1.0 + np.power(np.abs(x0t) + 1e-10, -4))\n",
    "              + 1.0 / (1.0 + np.power(np.abs(x1t) + 1e-10, -4)))\n",
    "    yt = np.nan_to_num(yt, nan=0.0, posinf=2.0, neginf=0.0)\n",
    "    return X_tr, y, np.array([x0t, x1t]), yt\n",
    "\n",
    "\n",
    "def load_vlad4(seed):\n",
    "    \"\"\"\n",
    "    Vladislavleva-4: 10 / (5 + Σ(xi - 3)²), 5D\n",
    "    Training: 1024 uniform random in [0.05, 6.05]\n",
    "    Test: 5000 uniform random in [-0.25, 6.35]\n",
    "    (exact GRAPE example_regression.py)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    X_tr = np.random.uniform(0.05, 6.05, (5, 1024))\n",
    "    Y_tr = np.array([\n",
    "        10.0 / (5.0 + sum((X_tr[k, i] - 3)**2 for k in range(5)))\n",
    "        for i in range(1024)\n",
    "    ])\n",
    "    X_te = np.random.uniform(-0.25, 6.35, (5, 5000))\n",
    "    Y_te = np.array([\n",
    "        10.0 / (5.0 + sum((X_te[k, i] - 3)**2 for k in range(5)))\n",
    "        for i in range(5000)\n",
    "    ])\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 10. FITNESS EVALUATION — MSE \n",
    "# ==========================================================================\n",
    "\n",
    "_EVAL_GLOBALS = {\n",
    "    'np': np, 'pdiv': pdiv, 'plog': plog, 'psqrt': psqrt, 'exp': exp,\n",
    "    '__builtins__': {},\n",
    "}\n",
    "\n",
    "\n",
    "def fitness_eval(ind, x, y):\n",
    "    \"\"\"\n",
    "    Evaluate fitness as MSE. Returns np.nan if invalid or error.\n",
    "    Exact reproduction of GRAPE's fitness_eval() (example_regression.py).\n",
    "    \"\"\"\n",
    "    if ind.invalid:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        pred = eval(ind.phenotype, _EVAL_GLOBALS, {'x': x})\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "    if not np.isrealobj(pred):\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        f = float(np.mean(np.square(y - pred)))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "    if f == float('inf') or np.isnan(f):\n",
    "        return np.nan\n",
    "    return f\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 11. SINGLE EVOLUTIONARY RUN\n",
    "# ==========================================================================\n",
    "\n",
    "def run_ge(init_method, grammar, X_tr, Y_tr, X_te, Y_te, seed):\n",
    "    \"\"\"Run one full GE evolution and return metrics.\"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    # --- Initialisation ---\n",
    "    if init_method == 'Random':\n",
    "        pop = random_initialisation(\n",
    "            POP_SIZE, grammar, MIN_INIT_GL, MAX_INIT_GL,\n",
    "            MAX_TREE_DEPTH, CODON_SIZE\n",
    "        )\n",
    "    else:\n",
    "        pop = sensible_initialisation(\n",
    "            POP_SIZE, grammar, MIN_INIT_DEPTH, MAX_INIT_DEPTH, CODON_SIZE\n",
    "        )\n",
    "\n",
    "    # Evaluate initial population\n",
    "    for ind in pop:\n",
    "        ind.fitness = fitness_eval(ind, X_tr, Y_tr)\n",
    "\n",
    "    # --- Initial stats ---\n",
    "    valid = [i for i in pop\n",
    "             if not i.invalid\n",
    "             and i.fitness is not None\n",
    "             and not np.isnan(i.fitness)]\n",
    "\n",
    "    init_stats = {\n",
    "        'validity': len(valid) / POP_SIZE,\n",
    "        'best_mse': float(min(i.fitness for i in valid)) if valid else np.nan,\n",
    "        'mean_mse': float(np.mean([i.fitness for i in valid])) if valid else np.nan,\n",
    "        'mean_depth': float(np.mean([i.depth for i in valid])) if valid else 0,\n",
    "        'mean_nodes': float(np.mean([i.nodes for i in valid])) if valid else 0,\n",
    "        'mean_gl': float(np.mean([len(i.genome) for i in valid])) if valid else 0,\n",
    "        'unique_pheno': len(set(i.phenotype for i in valid if i.phenotype)),\n",
    "        'struct_div': (len(set(tuple(i.structure) for i in valid))\n",
    "                       / max(len(valid), 1)) if valid else 0,\n",
    "    }\n",
    "\n",
    "    # --- History   ---\n",
    "    hist = {\n",
    "        'min': [], 'avg': [], 'invalid': [], 'fitness_test': [],\n",
    "        'avg_depth': [], 'avg_nodes': [], 'struct_div': [],\n",
    "    }\n",
    "\n",
    "    hof = None  # Hall of fame (best ever)\n",
    "\n",
    "    # --- Evolution loop ---\n",
    "    for gen in range(MAX_GENS + 1):\n",
    "        vp = [i for i in pop\n",
    "              if not i.invalid\n",
    "              and i.fitness is not None\n",
    "              and not np.isnan(i.fitness)]\n",
    "        fits = [i.fitness for i in vp]\n",
    "\n",
    "        # Update hall of fame\n",
    "        best = min(vp, key=lambda x: x.fitness) if vp else None\n",
    "        if best and (hof is None\n",
    "                     or best.fitness is not None\n",
    "                     and not np.isnan(best.fitness)\n",
    "                     and (hof.fitness is None\n",
    "                          or np.isnan(hof.fitness)\n",
    "                          or best.fitness < hof.fitness)):\n",
    "            hof = Individual(best.genome[:], grammar, MAX_TREE_DEPTH)\n",
    "            hof.fitness = best.fitness\n",
    "\n",
    "        # Test fitness of best\n",
    "        test_f = (fitness_eval(hof, X_te, Y_te)\n",
    "                  if hof and not hof.invalid else np.nan)\n",
    "\n",
    "        # Log generation stats\n",
    "        hist['min'].append(float(min(fits)) if fits else np.nan)\n",
    "        hist['avg'].append(float(np.mean(fits)) if fits else np.nan)\n",
    "        hist['invalid'].append(POP_SIZE - len(vp))\n",
    "        hist['fitness_test'].append(\n",
    "            float(test_f) if not np.isnan(test_f) else np.nan\n",
    "        )\n",
    "        hist['avg_depth'].append(\n",
    "            float(np.mean([i.depth for i in vp])) if vp else 0\n",
    "        )\n",
    "        hist['avg_nodes'].append(\n",
    "            float(np.mean([i.nodes for i in vp])) if vp else 0\n",
    "        )\n",
    "        hist['struct_div'].append(\n",
    "            len(set(tuple(i.structure) for i in vp))\n",
    "            / max(len(vp), 1) if vp else 0\n",
    "        )\n",
    "\n",
    "        if gen == MAX_GENS:\n",
    "            break\n",
    "\n",
    "        # --- Selection ---\n",
    "        sel = tournament_sel(pop, POP_SIZE, TOURN)\n",
    "\n",
    "        # --- Crossover ---\n",
    "        off = []\n",
    "        for i in range(0, len(sel) - 1, 2):\n",
    "            if random.random() < P_CX:\n",
    "                c0, c1 = crossover_onepoint(\n",
    "                    sel[i], sel[i + 1], grammar, MAX_TREE_DEPTH\n",
    "                )\n",
    "            else:\n",
    "                c0 = Individual(sel[i].genome[:], grammar, MAX_TREE_DEPTH)\n",
    "                c1 = Individual(sel[i + 1].genome[:], grammar, MAX_TREE_DEPTH)\n",
    "            off.extend([c0, c1])\n",
    "        if len(sel) % 2 == 1:\n",
    "            off.append(\n",
    "                Individual(sel[-1].genome[:], grammar, MAX_TREE_DEPTH)\n",
    "            )\n",
    "\n",
    "        # --- Mutation ---\n",
    "        mut = [\n",
    "            mutation_int_flip(i, P_MUT, CODON_SIZE, grammar, MAX_TREE_DEPTH)\n",
    "            for i in off\n",
    "        ]\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        for i in mut:\n",
    "            i.fitness = fitness_eval(i, X_tr, Y_tr)\n",
    "\n",
    "        pop = mut\n",
    "\n",
    "    # Final test evaluation\n",
    "    ft = (fitness_eval(hof, X_te, Y_te)\n",
    "          if hof and not hof.invalid else np.nan)\n",
    "\n",
    "    return {\n",
    "        'init': init_stats,\n",
    "        'hist': hist,\n",
    "        'train_mse': hof.fitness if hof else np.nan,\n",
    "        'test_mse': float(ft),\n",
    "        'pheno': hof.phenotype if hof else None,\n",
    "        'depth': hof.depth if hof else 0,\n",
    "        'nodes': hof.nodes if hof else 0,\n",
    "        'gl': len(hof.genome) if hof else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 12. RUN EXPERIMENT\n",
    "# ==========================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\" GE INITIALIZATION COMPARISON — BDS/GRAPE Setup\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\" Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(f\" Pop={POP_SIZE} Gens={MAX_GENS} Tourn={TOURN} \"\n",
    "          f\"CX={P_CX} Mut={P_MUT}\")\n",
    "    print(f\" Random genome=[{MIN_INIT_GL},{MAX_INIT_GL}]  \"\n",
    "          f\"Sensible depth=[{MIN_INIT_DEPTH},{MAX_INIT_DEPTH}]\")\n",
    "    print(f\" MaxTreeDepth={MAX_TREE_DEPTH} CodonSize={CODON_SIZE} \"\n",
    "          f\"Lazy mapper\")\n",
    "    print(f\" Fitness=MSE  N_RUNS={N_RUNS}\")\n",
    "\n",
    "    PROBLEMS = OrderedDict([\n",
    "        ('Pagie-1', {\n",
    "            'bnf': PAGIE1_BNF,\n",
    "            'loader': load_pagie1,\n",
    "            'desc': '1/(1+x^-4)+1/(1+y^-4), 2D grid'\n",
    "        }),\n",
    "        ('Vladislavleva-4', {\n",
    "            'bnf': VLAD4_BNF,\n",
    "            'loader': load_vlad4,\n",
    "            'desc': '10/(5+sum(xi-3)^2), 5D'\n",
    "        }),\n",
    "    ])\n",
    "\n",
    "    all_res = {}\n",
    "    t_start = time.time()\n",
    "\n",
    "    for pn, pi in PROBLEMS.items():\n",
    "        print(f\"\\n>>> {pn}: {pi['desc']}\")\n",
    "        gr = Grammar(pi['bnf'])\n",
    "\n",
    "        print(f\"    Grammar: {len(gr.non_terminals)} NTs, \"\n",
    "              f\"{sum(gr.n_rules)} total productions\")\n",
    "        for i, nt in enumerate(gr.non_terminals):\n",
    "            n = gr.n_rules[i]\n",
    "            rec = sum(1 for p in gr.production_rules[i] if p[4])\n",
    "            print(f\"      {nt}: {n} prods \"\n",
    "                  f\"(recursive={rec}, non-recursive={n - rec})\")\n",
    "\n",
    "        pr = {}\n",
    "        for method in ['Random', 'Sensible']:\n",
    "            t0 = time.time()\n",
    "            runs = []\n",
    "            for r in range(N_RUNS):\n",
    "                if (r + 1) % 5 == 0 or r == 0:\n",
    "                    print(f\"    {method} run {r + 1}/{N_RUNS}...\",\n",
    "                          flush=True)\n",
    "\n",
    "                np.random.seed(SEED + r)\n",
    "                X_tr, Y_tr, X_te, Y_te = pi['loader'](SEED + r)\n",
    "                result = run_ge(\n",
    "                    method, gr, X_tr, Y_tr, X_te, Y_te, SEED + r\n",
    "                )\n",
    "                runs.append(result)\n",
    "\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"    {method}: {elapsed:.0f}s \"\n",
    "                  f\"({elapsed / N_RUNS:.1f}s/run)\")\n",
    "            pr[method] = runs\n",
    "\n",
    "        all_res[pn] = pr\n",
    "\n",
    "    total_t = time.time() - t_start\n",
    "    print(f\"\\nTOTAL: {total_t / 60:.1f} min\")\n",
    "\n",
    "    # ==================================================================\n",
    "    # 13. STATISTICAL ANALYSIS\n",
    "    # ==================================================================\n",
    "\n",
    "    def sig_stars(p):\n",
    "        if p < 0.001:\n",
    "            return \"***\"\n",
    "        elif p < 0.01:\n",
    "            return \"**\"\n",
    "        elif p < 0.05:\n",
    "            return \"*\"\n",
    "        return \"ns\"\n",
    "\n",
    "    def vda(a, b):\n",
    "        \"\"\"Vargha-Delaney A effect size.\"\"\"\n",
    "        m, n = len(a), len(b)\n",
    "        if m == 0 or n == 0:\n",
    "            return 0.5\n",
    "        return sum(\n",
    "            1 if ai < bi else 0.5 if ai == bi else 0\n",
    "            for ai in a for bi in b\n",
    "        ) / (m * n)\n",
    "\n",
    "    def effect_label(a):\n",
    "        d = abs(a - 0.5)\n",
    "        if d < 0.06:\n",
    "            return \"negl\"\n",
    "        elif d < 0.14:\n",
    "            return \"small\"\n",
    "        elif d < 0.21:\n",
    "            return \"medium\"\n",
    "        return \"large\"\n",
    "\n",
    "    def safe_vals(lst):\n",
    "        return [x for x in lst\n",
    "                if x is not None and not np.isnan(x) and x < 1e10]\n",
    "\n",
    "    for pn, res in all_res.items():\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\" {pn}\")\n",
    "        print(f\"{'=' * 70}\")\n",
    "\n",
    "        metrics = [\n",
    "            (\"Init Validity %\",\n",
    "             lambda r: r['init']['validity'] * 100),\n",
    "            (\"Init Unique Pheno\",\n",
    "             lambda r: r['init']['unique_pheno']),\n",
    "            (\"Init Mean Depth\",\n",
    "             lambda r: r['init']['mean_depth']),\n",
    "            (\"Init Mean Nodes\",\n",
    "             lambda r: r['init']['mean_nodes']),\n",
    "            (\"Init Mean GenomeLen\",\n",
    "             lambda r: r['init']['mean_gl']),\n",
    "            (\"Init Struct Diversity\",\n",
    "             lambda r: r['init']['struct_div']),\n",
    "            (\"Init Best MSE\",\n",
    "             lambda r: r['init']['best_mse']),\n",
    "            (\"Init Mean MSE\",\n",
    "             lambda r: r['init']['mean_mse']),\n",
    "            (\"Final Train MSE\",\n",
    "             lambda r: r['train_mse']),\n",
    "            (\"Final Test MSE\",\n",
    "             lambda r: r['test_mse']),\n",
    "        ]\n",
    "\n",
    "        for label, extract in metrics:\n",
    "            rv = safe_vals([extract(r) for r in res['Random']])\n",
    "            svl = safe_vals([extract(r) for r in res['Sensible']])\n",
    "            if rv and svl:\n",
    "                _, p = mannwhitneyu(rv, svl, alternative='two-sided')\n",
    "                a = vda(rv, svl)\n",
    "                print(\n",
    "                    f\"  {label:<22}: \"\n",
    "                    f\"Rand={np.mean(rv):>10.4f}+-{np.std(rv):<8.4f}  \"\n",
    "                    f\"Sens={np.mean(svl):>10.4f}+-{np.std(svl):<8.4f}  \"\n",
    "                    f\"p={p:.4f}({sig_stars(p)}) A={a:.3f}({effect_label(a)})\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"  {label:<22}: insufficient data\")\n",
    "\n",
    "        print(f\"\\n  Best solutions found:\")\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            v = [r for r in res[m]\n",
    "                 if r['train_mse'] is not None\n",
    "                 and not np.isnan(r['train_mse'])]\n",
    "            if v:\n",
    "                b = min(v, key=lambda r: r['train_mse'])\n",
    "                ph = (b['pheno'] or 'N/A')[:120]\n",
    "                print(f\"    {m}: Train MSE={b['train_mse']:.6f}  \"\n",
    "                      f\"Test MSE={b['test_mse']:.6f}  \"\n",
    "                      f\"Depth={b['depth']}  Nodes={b['nodes']}\")\n",
    "                print(f\"      {ph}\")\n",
    "\n",
    "    # ==================================================================\n",
    "    # 14. PLOTS\n",
    "    # ==================================================================\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'axes.titlesize': 11,\n",
    "        'axes.labelsize': 10,\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.dpi': 300,\n",
    "        'savefig.bbox': 'tight',\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.3,\n",
    "        'lines.linewidth': 1.5,\n",
    "    })\n",
    "    n_probs = len(PROBLEMS)\n",
    "\n",
    "    # --- Fig 1: Initial Population Quality ---\n",
    "    fig, axes = plt.subplots(3, n_probs, figsize=(5 * n_probs, 10))\n",
    "    fig.suptitle(\n",
    "        'Initial Population Quality: Random vs Sensible (RHH)\\n'\n",
    "        '[GRAPE parameters: Pop=200, Lazy mapper, CodonSize=255]',\n",
    "        fontsize=13, fontweight='bold', y=1.02\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_res.items()):\n",
    "        for row, (ylabel, key) in enumerate([\n",
    "            ('Validity %', lambda r: r['init']['validity'] * 100),\n",
    "            ('Unique Phenotypes', lambda r: r['init']['unique_pheno']),\n",
    "            ('Mean Depth', lambda r: r['init']['mean_depth']),\n",
    "        ]):\n",
    "            ax = axes[row, col]\n",
    "            d = {m: safe_vals([key(r) for r in res[m]])\n",
    "                 for m in ['Random', 'Sensible']}\n",
    "            if d['Random'] and d['Sensible']:\n",
    "                bp = ax.boxplot(\n",
    "                    [d['Random'], d['Sensible']],\n",
    "                    positions=[1, 2], widths=0.6, patch_artist=True,\n",
    "                    medianprops=dict(color='black', linewidth=1.5)\n",
    "                )\n",
    "                for patch, m in zip(bp['boxes'], ['Random', 'Sensible']):\n",
    "                    patch.set_facecolor(COLORS[m])\n",
    "                    patch.set_alpha(0.7)\n",
    "                _, p = mannwhitneyu(d['Random'], d['Sensible'])\n",
    "                ax.text(\n",
    "                    1.5, ax.get_ylim()[1] * 0.97,\n",
    "                    f'p={p:.4f} ({sig_stars(p)})',\n",
    "                    ha='center', fontsize=8, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3',\n",
    "                              facecolor='lightyellow', alpha=0.8)\n",
    "                )\n",
    "            ax.set_xticks([1, 2])\n",
    "            ax.set_xticklabels(['Random', 'Sensible'])\n",
    "            ax.set_ylabel(ylabel)\n",
    "            if row == 0:\n",
    "                ax.set_title(pn)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig1_initial_quality.png')\n",
    "    plt.close()\n",
    "    print(\"\\nSaved: fig1_initial_quality.png\")\n",
    "\n",
    "    # --- Fig 2: Convergence curves ---\n",
    "    fig, axes = plt.subplots(2, n_probs, figsize=(5 * n_probs, 8))\n",
    "    fig.suptitle(\n",
    "        'Convergence: Best MSE & Structural Diversity (200 generations)',\n",
    "        fontsize=13, fontweight='bold', y=1.01\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_res.items()):\n",
    "        ng = len(res['Random'][0]['hist']['min'])\n",
    "        x_ax = np.arange(ng)\n",
    "\n",
    "        # Best MSE\n",
    "        ax = axes[0, col]\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            c = np.array([r['hist']['min'] for r in res[m]], dtype=float)\n",
    "            c = np.where(np.isnan(c) | (c > 1e8), np.nan, c)\n",
    "            mn = np.nanmean(c, axis=0)\n",
    "            sd = np.nanstd(c, axis=0)\n",
    "            ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "            ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                            color=COLORS[m], alpha=0.15)\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_ylabel('Best MSE (train)')\n",
    "        ax.set_title(pn)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "        # Structural diversity\n",
    "        ax = axes[1, col]\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            c = np.array([r['hist']['struct_div'] for r in res[m]])\n",
    "            mn = np.mean(c, axis=0)\n",
    "            sd = np.std(c, axis=0)\n",
    "            ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "            ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                            color=COLORS[m], alpha=0.15)\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_ylabel('Structural Diversity')\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig2_convergence.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig2_convergence.png\")\n",
    "\n",
    "    # --- Fig 3: Final fitness boxplots ---\n",
    "    fig, axes = plt.subplots(2, n_probs, figsize=(5 * n_probs, 7))\n",
    "    fig.suptitle(\n",
    "        'Final Fitness Distribution (30 runs x 200 generations)',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_res.items()):\n",
    "        for row, (ylabel, key) in enumerate([\n",
    "            ('Train MSE', lambda r: r['train_mse']),\n",
    "            ('Test MSE', lambda r: r['test_mse']),\n",
    "        ]):\n",
    "            ax = axes[row, col]\n",
    "            d = {m: safe_vals([key(r) for r in res[m]])\n",
    "                 for m in ['Random', 'Sensible']}\n",
    "            if d['Random'] and d['Sensible']:\n",
    "                bp = ax.boxplot(\n",
    "                    [d['Random'], d['Sensible']],\n",
    "                    labels=['Random', 'Sensible'],\n",
    "                    patch_artist=True,\n",
    "                    medianprops=dict(color='black', linewidth=1.5)\n",
    "                )\n",
    "                for patch, m in zip(bp['boxes'], ['Random', 'Sensible']):\n",
    "                    patch.set_facecolor(COLORS[m])\n",
    "                    patch.set_alpha(0.7)\n",
    "                _, p = mannwhitneyu(d['Random'], d['Sensible'])\n",
    "                a_val = vda(d['Random'], d['Sensible'])\n",
    "                ax.text(\n",
    "                    1.5, ax.get_ylim()[1] * 0.97,\n",
    "                    f'p={p:.4f} ({sig_stars(p)})\\nA={a_val:.3f}',\n",
    "                    ha='center', fontsize=8, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3',\n",
    "                              facecolor='lightyellow', alpha=0.8)\n",
    "                )\n",
    "            ax.set_ylabel(ylabel)\n",
    "            if row == 0:\n",
    "                ax.set_title(pn)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig3_boxplots.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig3_boxplots.png\")\n",
    "\n",
    "    # --- Fig 4: Depth & nodes over generations ---\n",
    "    fig, axes = plt.subplots(2, n_probs, figsize=(5 * n_probs, 7))\n",
    "    fig.suptitle(\n",
    "        'Population Structure Over Evolution',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_res.items()):\n",
    "        ng = len(res['Random'][0]['hist']['avg_depth'])\n",
    "        x_ax = np.arange(ng)\n",
    "        for row, (ylabel, key) in enumerate([\n",
    "            ('Avg Tree Depth', 'avg_depth'),\n",
    "            ('Avg Nodes', 'avg_nodes'),\n",
    "        ]):\n",
    "            ax = axes[row, col]\n",
    "            for m in ['Random', 'Sensible']:\n",
    "                c = np.array([r['hist'][key] for r in res[m]])\n",
    "                mn = np.mean(c, axis=0)\n",
    "                sd = np.std(c, axis=0)\n",
    "                ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "                ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                                color=COLORS[m], alpha=0.15)\n",
    "            ax.set_xlabel('Generation')\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.legend(fontsize=8)\n",
    "            if row == 0:\n",
    "                ax.set_title(pn)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig4_structure.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig4_structure.png\")\n",
    "\n",
    "    # --- Fig 5: Invalid individuals over generations ---\n",
    "    fig, axes = plt.subplots(1, n_probs, figsize=(5 * n_probs, 4))\n",
    "    fig.suptitle(\n",
    "        'Invalid Individuals Over Evolution',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_res.items()):\n",
    "        ax = axes[col] if n_probs > 1 else axes\n",
    "        ng = len(res['Random'][0]['hist']['invalid'])\n",
    "        x_ax = np.arange(ng)\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            c = np.array(\n",
    "                [r['hist']['invalid'] for r in res[m]], dtype=float\n",
    "            )\n",
    "            mn = np.mean(c, axis=0)\n",
    "            sd = np.std(c, axis=0)\n",
    "            ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "            ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                            color=COLORS[m], alpha=0.15)\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_ylabel('# Invalid')\n",
    "        ax.set_title(pn)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig5_invalids.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig5_invalids.png\")\n",
    "\n",
    "    # ==================================================================\n",
    "    # 15. SAVE DATA\n",
    "    # ==================================================================\n",
    "\n",
    "    def serialise(obj):\n",
    "        if isinstance(obj, (np.integer,)):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, (np.floating, float)):\n",
    "            return None if np.isnan(obj) else float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: serialise(v) for k, v in obj.items()}\n",
    "        if isinstance(obj, list):\n",
    "            return [serialise(v) for v in obj]\n",
    "        return obj\n",
    "\n",
    "    with open('ge_results_raw.json', 'w') as f:\n",
    "        json.dump(serialise(all_res), f)\n",
    "\n",
    "    config = {\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'source': 'Faithful reproduction of bdsul/grape parameters',\n",
    "        'parameters': {\n",
    "            'population_size': POP_SIZE,\n",
    "            'max_generations': MAX_GENS,\n",
    "            'p_crossover': P_CX,\n",
    "            'p_mutation': P_MUT,\n",
    "            'elite_size': ELITE,\n",
    "            'tournament_size': TOURN,\n",
    "            'max_tree_depth': MAX_TREE_DEPTH,\n",
    "            'codon_size': CODON_SIZE,\n",
    "            'codon_consumption': 'lazy',\n",
    "            'fitness_metric': 'MSE',\n",
    "            'random_init_genome_length': [MIN_INIT_GL, MAX_INIT_GL],\n",
    "            'sensible_init_depth': [MIN_INIT_DEPTH, MAX_INIT_DEPTH],\n",
    "            'sensible_method': 'Ramped Half-and-Half (RHH)',\n",
    "        },\n",
    "        'n_runs': N_RUNS,\n",
    "        'seed': SEED,\n",
    "        'total_seconds': total_t,\n",
    "        'problems': list(PROBLEMS.keys()),\n",
    "        'references': [\n",
    "            'Ryan & Azad (2003) Sensible initialisation in GE, '\n",
    "            'GECCO pp.142-145',\n",
    "            'Nicolau (2017) Understanding GE: initialisation, '\n",
    "            'GPEM 18(4) pp.467-507',\n",
    "            'de Lima et al. (2022) GRAPE, Signals 3(3) pp.642-663',\n",
    "            'Murphy et al. (2024) Structured GE Initialisation, GPEM 25(2)',\n",
    "        ],\n",
    "    }\n",
    "    with open('experiment_config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\" ALL DONE — {total_t / 60:.1f} min total\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    print(\" Output files:\")\n",
    "    print(\"   fig1_initial_quality.png\")\n",
    "    print(\"   fig2_convergence.png\")\n",
    "    print(\"   fig3_boxplots.png\")\n",
    "    print(\"   fig4_structure.png\")\n",
    "    print(\"   fig5_invalids.png\")\n",
    "    print(\"   ge_results_raw.json\")\n",
    "    print(\"   experiment_config.json\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
