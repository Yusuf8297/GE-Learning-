{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4c6aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " GRAMMATICAL EVOLUTION: INITIALIZATION METHODS COMPARISON\n",
      " (GRAPE-faithful core · Sequential · 4 benchmarks)\n",
      "======================================================================\n",
      "Experiment date : 2026-02-11 20:25\n",
      "GE library loaded\n",
      "======================================================================\n",
      " EXPERIMENTAL PARAMETERS (GRAPE)\n",
      "======================================================================\n",
      "  Runs           : 30\n",
      "  Generations    : 200\n",
      "  Population     : 200\n",
      "  Elite Size     : 0\n",
      "  Tournament     : 7\n",
      "  Crossover      : 0.8\n",
      "  Mutation Rate  : 0.01\n",
      "  Max Tree Depth : 35\n",
      "  Codon Size     : 255\n",
      "  Random genome  : [30, 50]\n",
      "  Sensible depth : [3, 13]\n",
      "  Mapper         : Lazy codon consumption\n",
      "  Fitness        : MSE\n",
      "======================================================================\n",
      "\n",
      "Benchmark Problems:\n",
      "  Keijzer-6: Harmonic series (1D)\n",
      "  Nguyen-7: ln(x+1)+ln(x²+1) (1D)\n",
      "  Pagie-1: 1/(1+x^-4)+1/(1+y^-4) (2D)\n",
      "  Diabetes: Sklearn benchmark (10D)\n",
      "\n",
      "======================================================================\n",
      " RUNNING EXPERIMENT (Sequential)\n",
      " 4 Problems × 2 Methods × 30 Runs = 240 jobs\n",
      "======================================================================\n",
      "\n",
      "############################################################\n",
      "# Keijzer-6: Harmonic series (1D)\n",
      "############################################################\n",
      "  Grammar: 2 NTs, 20 total productions\n",
      "    <e>: 10 prods (recursive=8, non-recursive=2)\n",
      "    <c>: 10 prods (recursive=0, non-recursive=10)\n",
      "  Random run 1/30...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1290\u001b[39m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m EXPERIMENT COMPLETE!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 823\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    821\u001b[39m     np.random.seed(SEED + r)\n\u001b[32m    822\u001b[39m     X_tr, Y_tr, X_te, Y_te = prob_info[\u001b[33m'\u001b[39m\u001b[33mloader\u001b[39m\u001b[33m'\u001b[39m]()\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     result = \u001b[43mrun_ge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_te\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    827\u001b[39m     runs.append(result)\n\u001b[32m    829\u001b[39m elapsed = time.time() - t0\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 755\u001b[39m, in \u001b[36mrun_ge\u001b[39m\u001b[34m(init_method, grammar, X_tr, Y_tr, X_te, Y_te, seed)\u001b[39m\n\u001b[32m    749\u001b[39m     off.append(\n\u001b[32m    750\u001b[39m         Individual(sel[-\u001b[32m1\u001b[39m].genome[:], grammar, MAX_TREE_DEPTH)\n\u001b[32m    751\u001b[39m     )\n\u001b[32m    753\u001b[39m \u001b[38;5;66;03m# --- Mutation ---\u001b[39;00m\n\u001b[32m    754\u001b[39m mut = [\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     \u001b[43mmutation_int_flip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_MUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCODON_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_TREE_DEPTH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m off\n\u001b[32m    757\u001b[39m ]\n\u001b[32m    759\u001b[39m \u001b[38;5;66;03m# --- Evaluate ---\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m mut:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 440\u001b[39m, in \u001b[36mmutation_int_flip\u001b[39m\u001b[34m(ind, mut_pb, codon_size, grammar, max_depth)\u001b[39m\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m random.random() < mut_pb:\n\u001b[32m    439\u001b[39m         g[i] = random.randint(\u001b[32m0\u001b[39m, codon_size)\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndividual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 290\u001b[39m, in \u001b[36mIndividual.__init__\u001b[39m\u001b[34m(self, genome, grammar, max_depth)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, genome, grammar, max_depth):\n\u001b[32m    287\u001b[39m     \u001b[38;5;28mself\u001b[39m.genome = genome\n\u001b[32m    288\u001b[39m     (\u001b[38;5;28mself\u001b[39m.phenotype, \u001b[38;5;28mself\u001b[39m.nodes, \u001b[38;5;28mself\u001b[39m.depth,\n\u001b[32m    289\u001b[39m      \u001b[38;5;28mself\u001b[39m.used_codons, \u001b[38;5;28mself\u001b[39m.invalid, \u001b[38;5;28mself\u001b[39m.n_wraps,\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m      \u001b[38;5;28mself\u001b[39m.structure) = \u001b[43mmapper_lazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m.fitness = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 268\u001b[39m, in \u001b[36mmapper_lazy\u001b[39m\u001b[34m(genome, grammar, max_depth)\u001b[39m\n\u001b[32m    263\u001b[39m             list_depth = (list_depth[:idx_depth]\n\u001b[32m    264\u001b[39m                           + [list_depth[idx_depth]] * ar\n\u001b[32m    265\u001b[39m                           + list_depth[idx_depth + \u001b[32m1\u001b[39m:])\n\u001b[32m    267\u001b[39m     nxt = re.search(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m<([\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw,\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m-.]+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m>\u001b[39m\u001b[33m\"\u001b[39m, phenotype)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     next_NT = \u001b[43mnxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m nxt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_NT:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m phenotype, nodes, \u001b[38;5;28mmax\u001b[39m(list_depth), \u001b[32m0\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[32m0\u001b[39m, structure\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "==========================================================================\n",
    " GRAMMATICAL EVOLUTION: INITIALIZATION METHODS COMPARISON\n",
    " GRAPE-faithful core · Sequential execution · 4 benchmarks\n",
    "\n",
    " GE core (Grammar, mapper, Individual, operators) faithfully reproduces\n",
    " the BDS Group's GRAPE codebase: https://github.com/bdsul/grape\n",
    " (de Lima et al., 2022, Signals 3(3), 642-663)\n",
    "\n",
    " Requirements:\n",
    "   pip install numpy scipy matplotlib scikit-learn\n",
    "\n",
    " Usage:\n",
    "   python ge_experiment_grape.py\n",
    "\n",
    " References:\n",
    "   [1] Ryan & Azad (2003) Sensible Initialisation in GE, GECCO\n",
    "   [2] Nicolau (2017) Understanding GE: Initialisation, GPEM 18(4)\n",
    "   [3] de Lima et al. (2022) GRAPE, Signals 3(3), 642-663\n",
    "   [4] Murphy et al. (2024) Structured GE Initialisation, GPEM 25(2)\n",
    "==========================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" GRAMMATICAL EVOLUTION: INITIALIZATION METHODS COMPARISON\")\n",
    "print(\" (GRAPE-faithful core · Sequential · 4 benchmarks)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Experiment date : {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  1. PROTECTED FUNCTIONS — exact copies from GRAPE functions.py\n",
    "# ==========================================================================\n",
    "\n",
    "def pdiv(a, b):\n",
    "    \"\"\"Protected division (GRAPE functions.py).\"\"\"\n",
    "    try:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            return np.where(b == 0, np.ones_like(a), a / b)\n",
    "    except ZeroDivisionError:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def plog(a):\n",
    "    \"\"\"Protected log: log(1+|a|) (GRAPE functions.py).\"\"\"\n",
    "    return np.log(1.0 + np.abs(a))\n",
    "\n",
    "\n",
    "def psqrt(a):\n",
    "    \"\"\"Protected sqrt: sqrt(|a|) (GRAPE functions.py).\"\"\"\n",
    "    return np.sqrt(abs(a))\n",
    "\n",
    "\n",
    "def exp(a):\n",
    "    \"\"\"Exponential with overflow protection.\"\"\"\n",
    "    return np.exp(np.clip(a, -500, 500))\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  2. GRAMMAR — reproducing GRAPE's Grammar class (grape.py)\n",
    "#\n",
    "#  Each production rule stored as:\n",
    "#    [0] string, [1] 'terminal'/'non-terminal', [2] arity,\n",
    "#    [3] production choice label, [4] recursive (bool),\n",
    "#    [5] min depth to terminate\n",
    "# ==========================================================================\n",
    "\n",
    "class Grammar:\n",
    "    \"\"\"Faithful reproduction of GRAPE's Grammar class.\"\"\"\n",
    "\n",
    "    def __init__(self, bnf_text):\n",
    "        bnf_grammar = re.sub(r\"\\s+\", \" \", bnf_text)\n",
    "\n",
    "        self.non_terminals = [\n",
    "            '<' + t + '>'\n",
    "            for t in re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\\s*::=\", bnf_grammar)\n",
    "        ]\n",
    "        self.start_rule = self.non_terminals[0]\n",
    "\n",
    "        for nt in self.non_terminals:\n",
    "            bnf_grammar = bnf_grammar.replace(nt + \" ::=\", \"  ::=\")\n",
    "        rules = bnf_grammar.split(\"::=\")[1:]\n",
    "        rules = [r.replace('\\n', '').replace('\\t', '') for r in rules]\n",
    "\n",
    "        self.production_rules = [r.split('|') for r in rules]\n",
    "        for i in range(len(self.production_rules)):\n",
    "            self.production_rules[i] = [\n",
    "                p.strip() for p in self.production_rules[i]\n",
    "            ]\n",
    "            for j in range(len(self.production_rules[i])):\n",
    "                pr_str = self.production_rules[i][j]\n",
    "                nts_in = re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", pr_str)\n",
    "                if nts_in:\n",
    "                    self.production_rules[i][j] = [\n",
    "                        pr_str, \"non-terminal\", len(nts_in), j\n",
    "                    ]\n",
    "                else:\n",
    "                    self.production_rules[i][j] = [\n",
    "                        pr_str, \"terminal\", 0, j\n",
    "                    ]\n",
    "\n",
    "        self.n_rules = [len(lst) for lst in self.production_rules]\n",
    "\n",
    "        # --- Recursiveness check (exact GRAPE logic) ---\n",
    "        for i in range(len(self.production_rules)):\n",
    "            for j in range(len(self.production_rules[i])):\n",
    "                nts = [\n",
    "                    '<' + t + '>'\n",
    "                    for t in re.findall(\n",
    "                        r\"\\<([\\(\\)\\w,\\-.]+)\\>\",\n",
    "                        self.production_rules[i][j][0]\n",
    "                    )\n",
    "                ]\n",
    "                recursive = False\n",
    "                for nt_c in list(dict.fromkeys(nts)):\n",
    "                    stack = [self.non_terminals[i]]\n",
    "                    if nt_c in stack:\n",
    "                        recursive = True\n",
    "                        break\n",
    "                    stack.append(nt_c)\n",
    "                    recursive = self._check_rec(nt_c, stack)\n",
    "                    if recursive:\n",
    "                        break\n",
    "                    stack.pop()\n",
    "                self.production_rules[i][j].append(recursive)  # index [4]\n",
    "\n",
    "        # --- Minimum depth to terminate (exact GRAPE logic) ---\n",
    "        nt_depth = [None] * len(self.non_terminals)\n",
    "        part_depth = []\n",
    "        isolated_nt = []\n",
    "        for i in range(len(self.production_rules)):\n",
    "            part_depth.append([])\n",
    "            isolated_nt.append([])\n",
    "            for j in range(len(self.production_rules[i])):\n",
    "                part_depth[i].append([])\n",
    "                isolated_nt[i].append([])\n",
    "                if self.production_rules[i][j][1] == 'terminal':\n",
    "                    isolated_nt[i][j].append(None)\n",
    "                    part_depth[i][j] = 1\n",
    "                    if not nt_depth[i]:\n",
    "                        nt_depth[i] = 1\n",
    "                else:\n",
    "                    for k in range(self.production_rules[i][j][2]):\n",
    "                        part_depth[i][j].append([])\n",
    "                        t = re.findall(\n",
    "                            r\"\\<([\\(\\)\\w,\\-.]+)\\>\",\n",
    "                            self.production_rules[i][j][0]\n",
    "                        )[k]\n",
    "                        isolated_nt[i][j].append('<' + t + '>')\n",
    "\n",
    "        cont = True\n",
    "        while cont:\n",
    "            if None not in nt_depth:\n",
    "                cont = False\n",
    "            for i in range(len(self.non_terminals)):\n",
    "                for j in range(len(self.production_rules)):\n",
    "                    for k in range(len(self.production_rules[j])):\n",
    "                        for l in range(len(isolated_nt[j][k])):\n",
    "                            if self.non_terminals[i] == isolated_nt[j][k][l]:\n",
    "                                if nt_depth[i] and not part_depth[j][k][l]:\n",
    "                                    part_depth[j][k][l] = nt_depth[i] + 1\n",
    "                                    if ([] not in part_depth[j][k]\n",
    "                                            and not nt_depth[j]):\n",
    "                                        nt_depth[j] = part_depth[j][k][l]\n",
    "\n",
    "        for i in range(len(part_depth)):\n",
    "            for j in range(len(part_depth[i])):\n",
    "                d = (part_depth[i][j]\n",
    "                     if isinstance(part_depth[i][j], int)\n",
    "                     else max(part_depth[i][j]))\n",
    "                self.production_rules[i][j].append(d)  # index [5]\n",
    "\n",
    "    def _check_rec(self, nt, stack):\n",
    "        \"\"\"Exact reproduction of GRAPE's check_recursiveness().\"\"\"\n",
    "        idx = self.non_terminals.index(nt)\n",
    "        for j in range(len(self.production_rules[idx])):\n",
    "            nts = [\n",
    "                '<' + t + '>'\n",
    "                for t in re.findall(\n",
    "                    r\"\\<([\\(\\)\\w,\\-.]+)\\>\",\n",
    "                    self.production_rules[idx][j][0]\n",
    "                )\n",
    "            ]\n",
    "            for nc in list(dict.fromkeys(nts)):\n",
    "                if nc in stack:\n",
    "                    return True\n",
    "                stack.append(nc)\n",
    "                if self._check_rec(nc, stack):\n",
    "                    return True\n",
    "                stack.pop()\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  3. MAPPER — lazy codon consumption (GRAPE default)\n",
    "# ==========================================================================\n",
    "\n",
    "def mapper_lazy(genome, grammar, max_depth):\n",
    "    \"\"\"\n",
    "    Lazy mapper: only consumes a codon when there are >1 production choices\n",
    "    for the current non-terminal. This is the GRAPE default.\n",
    "    \"\"\"\n",
    "    idx_genome = 0\n",
    "    phenotype = grammar.start_rule\n",
    "    nxt = re.search(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "    if not nxt:\n",
    "        return phenotype, 0, 1, 0, True, 0, []\n",
    "\n",
    "    next_NT = nxt.group()\n",
    "    n_start = len(re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype))\n",
    "    list_depth = [1] * n_start\n",
    "    idx_depth = 0\n",
    "    nodes = 0\n",
    "    structure = []\n",
    "\n",
    "    while next_NT and idx_genome < len(genome):\n",
    "        NT_i = grammar.non_terminals.index(next_NT)\n",
    "        n_opts = grammar.n_rules[NT_i]\n",
    "\n",
    "        if n_opts > 1:\n",
    "            idx_prod = genome[idx_genome] % n_opts\n",
    "            idx_genome += 1\n",
    "        else:\n",
    "            idx_prod = 0\n",
    "\n",
    "        pr = grammar.production_rules[NT_i][idx_prod]\n",
    "        structure.append(pr[3])\n",
    "        phenotype = phenotype.replace(next_NT, pr[0], 1)\n",
    "        list_depth[idx_depth] += 1\n",
    "\n",
    "        if list_depth[idx_depth] > max_depth:\n",
    "            break\n",
    "\n",
    "        if pr[2] == 0:  # terminal\n",
    "            idx_depth += 1\n",
    "            nodes += 1\n",
    "        elif pr[2] > 1:  # arity > 1\n",
    "            ar = pr[2]\n",
    "            if idx_depth == 0:\n",
    "                list_depth = [list_depth[0]] * ar + list_depth[1:]\n",
    "            else:\n",
    "                list_depth = (list_depth[:idx_depth]\n",
    "                              + [list_depth[idx_depth]] * ar\n",
    "                              + list_depth[idx_depth + 1:])\n",
    "\n",
    "        nxt = re.search(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "        next_NT = nxt.group() if nxt else None\n",
    "\n",
    "    if next_NT:\n",
    "        return phenotype, nodes, max(list_depth), 0, True, 0, structure\n",
    "    return phenotype, nodes, max(list_depth), idx_genome, False, 0, structure\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  4. INDIVIDUAL\n",
    "# ==========================================================================\n",
    "\n",
    "class Individual:\n",
    "    \"\"\"GE individual with genome-to-phenotype mapping.\"\"\"\n",
    "    __slots__ = [\n",
    "        'genome', 'phenotype', 'nodes', 'depth',\n",
    "        'used_codons', 'invalid', 'n_wraps', 'structure', 'fitness'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, genome, grammar, max_depth):\n",
    "        self.genome = genome\n",
    "        (self.phenotype, self.nodes, self.depth,\n",
    "         self.used_codons, self.invalid, self.n_wraps,\n",
    "         self.structure) = mapper_lazy(genome, grammar, max_depth)\n",
    "        self.fitness = None\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  5. INITIALISATION — exact GRAPE logic (grape.py)\n",
    "# ==========================================================================\n",
    "\n",
    "def random_initialisation(pop_size, grammar, min_gl, max_gl,\n",
    "                          max_depth, codon_size):\n",
    "    \"\"\"\n",
    "    Random initialisation: genome of random length [min_gl, max_gl]\n",
    "    with random integer codons in [0, codon_size].\n",
    "    \"\"\"\n",
    "    pop = []\n",
    "    for _ in range(pop_size):\n",
    "        gl = random.randint(min_gl, max_gl)\n",
    "        genome = [random.randint(0, codon_size) for _ in range(gl)]\n",
    "        pop.append(Individual(genome, grammar, max_depth))\n",
    "    return pop\n",
    "\n",
    "\n",
    "def sensible_initialisation(pop_size, grammar, min_d, max_d, codon_size):\n",
    "    \"\"\"\n",
    "    Sensible initialisation with Ramped Half-and-Half (RHH).\n",
    "    Half Grow (ramped across depths), half Full.\n",
    "    \"\"\"\n",
    "    is_odd = pop_size % 2\n",
    "    n_grow = pop_size // 2\n",
    "    n_sets = max_d - min_d + 1\n",
    "    set_sz = n_grow // n_sets\n",
    "    remaining = n_grow % n_sets\n",
    "    n_full = n_grow + is_odd + remaining\n",
    "\n",
    "    pop = []\n",
    "\n",
    "    # Grow (ramped)\n",
    "    for i in range(n_sets):\n",
    "        md = min_d + i\n",
    "        for _ in range(set_sz):\n",
    "            pop.append(_build_tree(grammar, md, codon_size, 'grow'))\n",
    "\n",
    "    # Full\n",
    "    for _ in range(n_full):\n",
    "        pop.append(_build_tree(grammar, max_d, codon_size, 'full'))\n",
    "\n",
    "    return pop\n",
    "\n",
    "\n",
    "def _build_tree(grammar, max_depth, codon_size, method):\n",
    "    \"\"\"Build one individual using grow or full method (GRAPE style).\"\"\"\n",
    "    remainders = []\n",
    "    possible_choices = []\n",
    "\n",
    "    phenotype = grammar.start_rule\n",
    "    rem_NTs = [\n",
    "        '<' + t + '>'\n",
    "        for t in re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "    ]\n",
    "    depths = [1] * len(rem_NTs)\n",
    "    idx_b = 0\n",
    "\n",
    "    while rem_NTs:\n",
    "        idx_NT = grammar.non_terminals.index(rem_NTs[0])\n",
    "        total = grammar.production_rules[idx_NT]\n",
    "        actual = [pr for pr in total\n",
    "                  if pr[5] + depths[idx_b] <= max_depth]\n",
    "\n",
    "        if not actual:\n",
    "            actual = [pr for pr in total if pr[1] == 'terminal']\n",
    "            if not actual:\n",
    "                actual = total\n",
    "\n",
    "        if method == 'full':\n",
    "            rec = [pr for pr in actual if pr[4]]\n",
    "            ch = random.choice(rec) if rec else random.choice(actual)\n",
    "        else:\n",
    "            ch = random.choice(actual)\n",
    "\n",
    "        phenotype = phenotype.replace(rem_NTs[0], ch[0], 1)\n",
    "        depths[idx_b] += 1\n",
    "\n",
    "        if len(total) > 1:\n",
    "            remainders.append(ch[3])\n",
    "            possible_choices.append(len(total))\n",
    "\n",
    "        if ch[2] > 1:\n",
    "            ar = ch[2]\n",
    "            if idx_b == 0:\n",
    "                depths = [depths[0]] * ar + depths[1:]\n",
    "            else:\n",
    "                depths = (depths[:idx_b]\n",
    "                          + [depths[idx_b]] * ar\n",
    "                          + depths[idx_b + 1:])\n",
    "\n",
    "        if ch[1] == 'terminal':\n",
    "            idx_b += 1\n",
    "\n",
    "        rem_NTs = [\n",
    "            '<' + t + '>'\n",
    "            for t in re.findall(r\"\\<([\\(\\)\\w,\\-.]+)\\>\", phenotype)\n",
    "        ]\n",
    "\n",
    "    genome = []\n",
    "    for k in range(len(remainders)):\n",
    "        codon = (\n",
    "            random.randint(0, int(1e10))\n",
    "            % math.floor((codon_size + 1) / possible_choices[k])\n",
    "            * possible_choices[k]\n",
    "        ) + remainders[k]\n",
    "        genome.append(codon)\n",
    "\n",
    "    tail = max(int(0.5 * len(genome)), 1)\n",
    "    for _ in range(tail):\n",
    "        genome.append(random.randint(0, codon_size))\n",
    "\n",
    "    return Individual(genome, grammar, max_depth)\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  6. GENETIC OPERATORS\n",
    "# ==========================================================================\n",
    "\n",
    "def crossover_onepoint(p0, p1, grammar, max_depth):\n",
    "    \"\"\"One-point crossover within the effective genome (GRAPE style).\"\"\"\n",
    "    cx0 = max(1, min(len(p0.genome), p0.used_codons)\n",
    "              if not p0.invalid else len(p0.genome))\n",
    "    cx1 = max(1, min(len(p1.genome), p1.used_codons)\n",
    "              if not p1.invalid else len(p1.genome))\n",
    "\n",
    "    for _ in range(20):\n",
    "        pt0 = random.randint(1, cx0)\n",
    "        pt1 = random.randint(1, cx1)\n",
    "        g0 = p0.genome[:pt0] + p1.genome[pt1:]\n",
    "        g1 = p1.genome[:pt1] + p0.genome[pt0:]\n",
    "        c0 = Individual(g0, grammar, max_depth)\n",
    "        c1 = Individual(g1, grammar, max_depth)\n",
    "        if c0.depth <= max_depth and c1.depth <= max_depth:\n",
    "            return c0, c1\n",
    "\n",
    "    return (Individual(p0.genome[:], grammar, max_depth),\n",
    "            Individual(p1.genome[:], grammar, max_depth))\n",
    "\n",
    "\n",
    "def mutation_int_flip(ind, mut_pb, codon_size, grammar, max_depth):\n",
    "    \"\"\"Per-codon integer flip mutation (GRAPE style).\"\"\"\n",
    "    g = ind.genome[:]\n",
    "    for i in range(len(g)):\n",
    "        if random.random() < mut_pb:\n",
    "            g[i] = random.randint(0, codon_size)\n",
    "    return Individual(g, grammar, max_depth)\n",
    "\n",
    "\n",
    "def tournament_sel(pop, k, ts):\n",
    "    \"\"\"Standard tournament selection.\"\"\"\n",
    "    sel = []\n",
    "    for _ in range(k):\n",
    "        asp = random.sample(pop, min(ts, len(pop)))\n",
    "        sel.append(min(\n",
    "            asp,\n",
    "            key=lambda x: (x.fitness\n",
    "                           if x.fitness is not None and not np.isnan(x.fitness)\n",
    "                           else float('inf'))\n",
    "        ))\n",
    "    return sel\n",
    "\n",
    "\n",
    "print(\"GE library loaded\")\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  7. EXPERIMENTAL PARAMETERS (GRAPE defaults)\n",
    "# ==========================================================================\n",
    "\n",
    "POP_SIZE       = 200\n",
    "MAX_GENS       = 200\n",
    "P_CX           = 0.8\n",
    "P_MUT          = 0.01\n",
    "ELITE          = 0\n",
    "TOURN          = 7\n",
    "\n",
    "MIN_INIT_GL    = 30    # Random init genome length\n",
    "MAX_INIT_GL    = 50    # Random init genome length\n",
    "MAX_INIT_DEPTH = 13    # Sensible init max depth\n",
    "MIN_INIT_DEPTH = 3     # Sensible init min depth\n",
    "MAX_TREE_DEPTH = 35    # Runtime depth limit\n",
    "CODON_SIZE     = 255\n",
    "\n",
    "N_RUNS         = 30\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" EXPERIMENTAL PARAMETERS (GRAPE)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Runs           : {N_RUNS}\")\n",
    "print(f\"  Generations    : {MAX_GENS}\")\n",
    "print(f\"  Population     : {POP_SIZE}\")\n",
    "print(f\"  Elite Size     : {ELITE}\")\n",
    "print(f\"  Tournament     : {TOURN}\")\n",
    "print(f\"  Crossover      : {P_CX}\")\n",
    "print(f\"  Mutation Rate  : {P_MUT}\")\n",
    "print(f\"  Max Tree Depth : {MAX_TREE_DEPTH}\")\n",
    "print(f\"  Codon Size     : {CODON_SIZE}\")\n",
    "print(f\"  Random genome  : [{MIN_INIT_GL}, {MAX_INIT_GL}]\")\n",
    "print(f\"  Sensible depth : [{MIN_INIT_DEPTH}, {MAX_INIT_DEPTH}]\")\n",
    "print(f\"  Mapper         : Lazy codon consumption\")\n",
    "print(f\"  Fitness        : MSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "COLORS = {'Random': '#E74C3C', 'Sensible': '#3498DB'}\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  8. GRAMMARS — GRAPE-style BNF (x[i] indexing)\n",
    "# ==========================================================================\n",
    "\n",
    "def make_grammar_bnf(n_features):\n",
    "    \"\"\"\n",
    "    Build a GRAPE-style BNF grammar string for the given dimensionality.\n",
    "    Uses x[0], x[1], ... notation and GRAPE protected operators.\n",
    "    \"\"\"\n",
    "    vars_list = ' | '.join([f'x[{i}]' for i in range(n_features)])\n",
    "\n",
    "    bnf = (\n",
    "        \"<e> ::= <e>+<e> | <e>-<e> | <e>*<e> | pdiv(<e>,<e>) | \"\n",
    "        \"psqrt(<e>) | np.sin(<e>) | np.tanh(<e>) | plog(<e>) | \"\n",
    "        f\"{vars_list} | <c><c>.<c><c>\\n\"\n",
    "        \"<c> ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\"\n",
    "    )\n",
    "    return bnf\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "#  9. BENCHMARK PROBLEMS\n",
    "#     Data stored in GRAPE format: X shape = (n_features, n_samples)\n",
    "# ==========================================================================\n",
    "\n",
    "def load_keijzer6():\n",
    "    \"\"\"Keijzer-6: sum(1/i, i=1..x), univariate.\"\"\"\n",
    "    def keijzer_6(x):\n",
    "        return np.array([sum(1.0 / i for i in range(1, int(xi) + 1))\n",
    "                         for xi in x])\n",
    "\n",
    "    x_tr = np.linspace(1, 50, 50)\n",
    "    y_tr = keijzer_6(x_tr)\n",
    "    x_te = np.linspace(1, 120, 120)\n",
    "    y_te = keijzer_6(x_te)\n",
    "    # GRAPE format: (n_features, n_samples)\n",
    "    return np.array([x_tr]), y_tr, np.array([x_te]), y_te\n",
    "\n",
    "\n",
    "def load_nguyen7():\n",
    "    \"\"\"Nguyen-7: ln(x+1) + ln(x²+1), univariate.\"\"\"\n",
    "    x_tr = np.linspace(0, 2, 20)\n",
    "    y_tr = np.log(x_tr + 1) + np.log(x_tr ** 2 + 1)\n",
    "    x_te = np.linspace(0, 2, 100)\n",
    "    y_te = np.log(x_te + 1) + np.log(x_te ** 2 + 1)\n",
    "    return np.array([x_tr]), y_tr, np.array([x_te]), y_te\n",
    "\n",
    "\n",
    "def load_pagie1():\n",
    "    \"\"\"Pagie-1: 1/(1+x^-4) + 1/(1+y^-4), 2D grid.\"\"\"\n",
    "    vals = np.linspace(-5, 5, 26)  # 676 training points\n",
    "    X0, X1 = np.meshgrid(vals, vals)\n",
    "    x0, x1 = X0.ravel(), X1.ravel()\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        y = (1.0 / (1.0 + np.power(np.abs(x0) + 1e-10, -4))\n",
    "             + 1.0 / (1.0 + np.power(np.abs(x1) + 1e-10, -4)))\n",
    "    y = np.nan_to_num(y, nan=0.0, posinf=2.0, neginf=0.0)\n",
    "\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    x0t = rng.uniform(-5, 5, 10000)\n",
    "    x1t = rng.uniform(-5, 5, 10000)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        yt = (1.0 / (1.0 + np.power(np.abs(x0t) + 1e-10, -4))\n",
    "              + 1.0 / (1.0 + np.power(np.abs(x1t) + 1e-10, -4)))\n",
    "    yt = np.nan_to_num(yt, nan=0.0, posinf=2.0, neginf=0.0)\n",
    "    return np.array([x0, x1]), y, np.array([x0t, x1t]), yt\n",
    "\n",
    "\n",
    "def load_diabetes():\n",
    "    \"\"\"Sklearn Diabetes dataset (10 features).\"\"\"\n",
    "    from sklearn.datasets import load_diabetes as _load\n",
    "    data = _load()\n",
    "    X, y = data.data, data.target\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=SEED)\n",
    "    # Transpose to GRAPE format: (n_features, n_samples)\n",
    "    return X_tr.T, y_tr, X_te.T, y_te\n",
    "\n",
    "\n",
    "PROBLEMS = OrderedDict([\n",
    "    ('Keijzer-6', {\n",
    "        'loader': load_keijzer6,\n",
    "        'n_features': 1,\n",
    "        'desc': 'Harmonic series (1D)',\n",
    "    }),\n",
    "    ('Nguyen-7', {\n",
    "        'loader': load_nguyen7,\n",
    "        'n_features': 1,\n",
    "        'desc': 'ln(x+1)+ln(x²+1) (1D)',\n",
    "    }),\n",
    "    ('Pagie-1', {\n",
    "        'loader': load_pagie1,\n",
    "        'n_features': 2,\n",
    "        'desc': '1/(1+x^-4)+1/(1+y^-4) (2D)',\n",
    "    }),\n",
    "    ('Diabetes', {\n",
    "        'loader': load_diabetes,\n",
    "        'n_features': 10,\n",
    "        'desc': 'Sklearn benchmark (10D)',\n",
    "    }),\n",
    "])\n",
    "\n",
    "print(\"\\nBenchmark Problems:\")\n",
    "for name, info in PROBLEMS.items():\n",
    "    print(f\"  {name}: {info['desc']}\")\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 10. FITNESS EVALUATION — MSE (GRAPE style)\n",
    "# ==========================================================================\n",
    "\n",
    "_EVAL_GLOBALS = {\n",
    "    'np': np, 'pdiv': pdiv, 'plog': plog, 'psqrt': psqrt, 'exp': exp,\n",
    "    '__builtins__': {},\n",
    "}\n",
    "\n",
    "\n",
    "def fitness_eval(ind, x, y):\n",
    "    \"\"\"Evaluate fitness as MSE. Returns np.nan if invalid or error.\"\"\"\n",
    "    if ind.invalid:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        pred = eval(ind.phenotype, _EVAL_GLOBALS, {'x': x})\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "    if not np.isrealobj(pred):\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        f = float(np.mean(np.square(y - pred)))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "    if f == float('inf') or np.isnan(f):\n",
    "        return np.nan\n",
    "    return f\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 11. SINGLE EVOLUTIONARY RUN\n",
    "# ==========================================================================\n",
    "\n",
    "def run_ge(init_method, grammar, X_tr, Y_tr, X_te, Y_te, seed):\n",
    "    \"\"\"Run one full GE evolution and return metrics.\"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    # --- Initialisation ---\n",
    "    if init_method == 'Random':\n",
    "        pop = random_initialisation(\n",
    "            POP_SIZE, grammar, MIN_INIT_GL, MAX_INIT_GL,\n",
    "            MAX_TREE_DEPTH, CODON_SIZE\n",
    "        )\n",
    "    else:\n",
    "        pop = sensible_initialisation(\n",
    "            POP_SIZE, grammar, MIN_INIT_DEPTH, MAX_INIT_DEPTH, CODON_SIZE\n",
    "        )\n",
    "\n",
    "    # Evaluate initial population\n",
    "    for ind in pop:\n",
    "        ind.fitness = fitness_eval(ind, X_tr, Y_tr)\n",
    "\n",
    "    # --- Initial stats ---\n",
    "    valid = [i for i in pop\n",
    "             if not i.invalid\n",
    "             and i.fitness is not None\n",
    "             and not np.isnan(i.fitness)]\n",
    "\n",
    "    init_stats = {\n",
    "        'validity': len(valid) / POP_SIZE,\n",
    "        'best_mse': float(min(i.fitness for i in valid)) if valid else np.nan,\n",
    "        'mean_mse': float(np.mean([i.fitness for i in valid])) if valid else np.nan,\n",
    "        'mean_depth': float(np.mean([i.depth for i in valid])) if valid else 0,\n",
    "        'mean_nodes': float(np.mean([i.nodes for i in valid])) if valid else 0,\n",
    "        'mean_gl': float(np.mean([len(i.genome) for i in valid])) if valid else 0,\n",
    "        'unique_pheno': len(set(i.phenotype for i in valid if i.phenotype)),\n",
    "        'struct_div': (len(set(tuple(i.structure) for i in valid))\n",
    "                       / max(len(valid), 1)) if valid else 0,\n",
    "    }\n",
    "\n",
    "    # --- History ---\n",
    "    hist = {\n",
    "        'min': [], 'avg': [], 'invalid': [], 'fitness_test': [],\n",
    "        'avg_depth': [], 'avg_nodes': [], 'struct_div': [],\n",
    "    }\n",
    "\n",
    "    hof = None  # Hall of fame (best ever)\n",
    "\n",
    "    # --- Evolution loop ---\n",
    "    for gen in range(MAX_GENS + 1):\n",
    "        vp = [i for i in pop\n",
    "              if not i.invalid\n",
    "              and i.fitness is not None\n",
    "              and not np.isnan(i.fitness)]\n",
    "        fits = [i.fitness for i in vp]\n",
    "\n",
    "        # Update hall of fame\n",
    "        best = min(vp, key=lambda x: x.fitness) if vp else None\n",
    "        if best and (hof is None\n",
    "                     or best.fitness is not None\n",
    "                     and not np.isnan(best.fitness)\n",
    "                     and (hof.fitness is None\n",
    "                          or np.isnan(hof.fitness)\n",
    "                          or best.fitness < hof.fitness)):\n",
    "            hof = Individual(best.genome[:], grammar, MAX_TREE_DEPTH)\n",
    "            hof.fitness = best.fitness\n",
    "\n",
    "        # Test fitness of best\n",
    "        test_f = (fitness_eval(hof, X_te, Y_te)\n",
    "                  if hof and not hof.invalid else np.nan)\n",
    "\n",
    "        # Log generation stats\n",
    "        hist['min'].append(float(min(fits)) if fits else np.nan)\n",
    "        hist['avg'].append(float(np.mean(fits)) if fits else np.nan)\n",
    "        hist['invalid'].append(POP_SIZE - len(vp))\n",
    "        hist['fitness_test'].append(\n",
    "            float(test_f) if not np.isnan(test_f) else np.nan\n",
    "        )\n",
    "        hist['avg_depth'].append(\n",
    "            float(np.mean([i.depth for i in vp])) if vp else 0\n",
    "        )\n",
    "        hist['avg_nodes'].append(\n",
    "            float(np.mean([i.nodes for i in vp])) if vp else 0\n",
    "        )\n",
    "        hist['struct_div'].append(\n",
    "            len(set(tuple(i.structure) for i in vp))\n",
    "            / max(len(vp), 1) if vp else 0\n",
    "        )\n",
    "\n",
    "        if gen == MAX_GENS:\n",
    "            break\n",
    "\n",
    "        # --- Selection ---\n",
    "        sel = tournament_sel(pop, POP_SIZE, TOURN)\n",
    "\n",
    "        # --- Crossover ---\n",
    "        off = []\n",
    "        for i in range(0, len(sel) - 1, 2):\n",
    "            if random.random() < P_CX:\n",
    "                c0, c1 = crossover_onepoint(\n",
    "                    sel[i], sel[i + 1], grammar, MAX_TREE_DEPTH\n",
    "                )\n",
    "            else:\n",
    "                c0 = Individual(sel[i].genome[:], grammar, MAX_TREE_DEPTH)\n",
    "                c1 = Individual(sel[i + 1].genome[:], grammar, MAX_TREE_DEPTH)\n",
    "            off.extend([c0, c1])\n",
    "        if len(sel) % 2 == 1:\n",
    "            off.append(\n",
    "                Individual(sel[-1].genome[:], grammar, MAX_TREE_DEPTH)\n",
    "            )\n",
    "\n",
    "        # --- Mutation ---\n",
    "        mut = [\n",
    "            mutation_int_flip(i, P_MUT, CODON_SIZE, grammar, MAX_TREE_DEPTH)\n",
    "            for i in off\n",
    "        ]\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        for i in mut:\n",
    "            i.fitness = fitness_eval(i, X_tr, Y_tr)\n",
    "\n",
    "        pop = mut\n",
    "\n",
    "    # Final test evaluation\n",
    "    ft = (fitness_eval(hof, X_te, Y_te)\n",
    "          if hof and not hof.invalid else np.nan)\n",
    "\n",
    "    return {\n",
    "        'init': init_stats,\n",
    "        'hist': hist,\n",
    "        'train_mse': hof.fitness if hof else np.nan,\n",
    "        'test_mse': float(ft),\n",
    "        'pheno': hof.phenotype if hof else None,\n",
    "        'depth': hof.depth if hof else 0,\n",
    "        'nodes': hof.nodes if hof else 0,\n",
    "        'gl': len(hof.genome) if hof else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 12. RUN EXPERIMENT — SEQUENTIAL\n",
    "# ==========================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\" RUNNING EXPERIMENT (Sequential)\")\n",
    "    print(f\" {len(PROBLEMS)} Problems × 2 Methods × {N_RUNS} Runs\"\n",
    "          f\" = {len(PROBLEMS)*2*N_RUNS} jobs\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    all_results = {}\n",
    "    total_start = time.time()\n",
    "\n",
    "    for prob_name, prob_info in PROBLEMS.items():\n",
    "        print(f\"\\n{'#' * 60}\")\n",
    "        print(f\"# {prob_name}: {prob_info['desc']}\")\n",
    "        print(f\"{'#' * 60}\")\n",
    "\n",
    "        bnf = make_grammar_bnf(prob_info['n_features'])\n",
    "        grammar = Grammar(bnf)\n",
    "\n",
    "        print(f\"  Grammar: {len(grammar.non_terminals)} NTs, \"\n",
    "              f\"{sum(grammar.n_rules)} total productions\")\n",
    "        for i, nt in enumerate(grammar.non_terminals):\n",
    "            n = grammar.n_rules[i]\n",
    "            rec = sum(1 for p in grammar.production_rules[i] if p[4])\n",
    "            print(f\"    {nt}: {n} prods \"\n",
    "                  f\"(recursive={rec}, non-recursive={n - rec})\")\n",
    "\n",
    "        problem_results = {}\n",
    "\n",
    "        for method_name in ['Random', 'Sensible']:\n",
    "            t0 = time.time()\n",
    "            runs = []\n",
    "            for r in range(N_RUNS):\n",
    "                if (r + 1) % 5 == 0 or r == 0:\n",
    "                    print(f\"  {method_name} run {r + 1}/{N_RUNS}...\",\n",
    "                          flush=True)\n",
    "\n",
    "                np.random.seed(SEED + r)\n",
    "                X_tr, Y_tr, X_te, Y_te = prob_info['loader']()\n",
    "                result = run_ge(\n",
    "                    method_name, grammar, X_tr, Y_tr, X_te, Y_te,\n",
    "                    SEED + r\n",
    "                )\n",
    "                runs.append(result)\n",
    "\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"  {method_name}: {elapsed:.0f}s \"\n",
    "                  f\"({elapsed / N_RUNS:.1f}s/run)\")\n",
    "            problem_results[method_name] = runs\n",
    "\n",
    "        all_results[prob_name] = problem_results\n",
    "\n",
    "    total_t = time.time() - total_start\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\" ALL RUNS COMPLETED in {total_t / 60:.1f} minutes\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    # ==================================================================\n",
    "    # 13. STATISTICAL ANALYSIS\n",
    "    # ==================================================================\n",
    "\n",
    "    def sig_stars(p):\n",
    "        if p < 0.001:\n",
    "            return \"***\"\n",
    "        elif p < 0.01:\n",
    "            return \"**\"\n",
    "        elif p < 0.05:\n",
    "            return \"*\"\n",
    "        return \"ns\"\n",
    "\n",
    "    def vda(a, b):\n",
    "        \"\"\"Vargha-Delaney A effect size.\"\"\"\n",
    "        m, n = len(a), len(b)\n",
    "        if m == 0 or n == 0:\n",
    "            return 0.5\n",
    "        return sum(\n",
    "            1 if ai < bi else 0.5 if ai == bi else 0\n",
    "            for ai in a for bi in b\n",
    "        ) / (m * n)\n",
    "\n",
    "    def effect_label(a):\n",
    "        d = abs(a - 0.5)\n",
    "        if d < 0.06:\n",
    "            return \"negl\"\n",
    "        elif d < 0.14:\n",
    "            return \"small\"\n",
    "        elif d < 0.21:\n",
    "            return \"medium\"\n",
    "        return \"large\"\n",
    "\n",
    "    def safe_vals(lst):\n",
    "        return [x for x in lst\n",
    "                if x is not None and not np.isnan(x) and x < 1e10]\n",
    "\n",
    "    # --- Per-problem detailed analysis ---\n",
    "    for pn, res in all_results.items():\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\" {pn}\")\n",
    "        print(f\"{'=' * 70}\")\n",
    "\n",
    "        metrics = [\n",
    "            (\"Init Validity %\",\n",
    "             lambda r: r['init']['validity'] * 100),\n",
    "            (\"Init Unique Pheno\",\n",
    "             lambda r: r['init']['unique_pheno']),\n",
    "            (\"Init Mean Depth\",\n",
    "             lambda r: r['init']['mean_depth']),\n",
    "            (\"Init Mean Nodes\",\n",
    "             lambda r: r['init']['mean_nodes']),\n",
    "            (\"Init Mean GenomeLen\",\n",
    "             lambda r: r['init']['mean_gl']),\n",
    "            (\"Init Struct Diversity\",\n",
    "             lambda r: r['init']['struct_div']),\n",
    "            (\"Init Best MSE\",\n",
    "             lambda r: r['init']['best_mse']),\n",
    "            (\"Init Mean MSE\",\n",
    "             lambda r: r['init']['mean_mse']),\n",
    "            (\"Final Train MSE\",\n",
    "             lambda r: r['train_mse']),\n",
    "            (\"Final Test MSE\",\n",
    "             lambda r: r['test_mse']),\n",
    "        ]\n",
    "\n",
    "        for label, extract in metrics:\n",
    "            rv = safe_vals([extract(r) for r in res['Random']])\n",
    "            svl = safe_vals([extract(r) for r in res['Sensible']])\n",
    "            if rv and svl:\n",
    "                _, p = mannwhitneyu(rv, svl, alternative='two-sided')\n",
    "                a = vda(rv, svl)\n",
    "                print(\n",
    "                    f\"  {label:<22}: \"\n",
    "                    f\"Rand={np.mean(rv):>10.4f}+-{np.std(rv):<8.4f}  \"\n",
    "                    f\"Sens={np.mean(svl):>10.4f}+-{np.std(svl):<8.4f}  \"\n",
    "                    f\"p={p:.4f}({sig_stars(p)}) A={a:.3f}({effect_label(a)})\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"  {label:<22}: insufficient data\")\n",
    "\n",
    "        print(f\"\\n  Best solutions found:\")\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            v = [r for r in res[m]\n",
    "                 if r['train_mse'] is not None\n",
    "                 and not np.isnan(r['train_mse'])]\n",
    "            if v:\n",
    "                b = min(v, key=lambda r: r['train_mse'])\n",
    "                ph = (b['pheno'] or 'N/A')[:120]\n",
    "                print(f\"    {m}: Train MSE={b['train_mse']:.6f}  \"\n",
    "                      f\"Test MSE={b['test_mse']:.6f}  \"\n",
    "                      f\"Depth={b['depth']}  Nodes={b['nodes']}\")\n",
    "                print(f\"      {ph}\")\n",
    "\n",
    "    # --- Comprehensive summary tables ---\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" COMPREHENSIVE RESULTS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    prob_names = list(all_results.keys())\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" INITIAL POPULATION VALIDITY (%)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Problem':<15} {'Random':>15} {'Sensible':>15} {'p-value':>12} {'Sig':>6}\")\n",
    "    print(\"-\" * 80)\n",
    "    for p in prob_names:\n",
    "        rv = safe_vals([r['init']['validity'] * 100\n",
    "                        for r in all_results[p]['Random']])\n",
    "        sv = safe_vals([r['init']['validity'] * 100\n",
    "                        for r in all_results[p]['Sensible']])\n",
    "        if rv and sv:\n",
    "            _, pval = mannwhitneyu(rv, sv)\n",
    "            sig = sig_stars(pval)\n",
    "            print(f\"{p:<15} {np.mean(rv):>6.1f} +- {np.std(rv):>4.1f} \"\n",
    "                  f\"{np.mean(sv):>6.1f} +- {np.std(sv):>4.1f} \"\n",
    "                  f\"{pval:>12.6f} {sig:>6}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" FINAL TRAIN MSE\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Problem':<15} {'Random':>15} {'Sensible':>15} {'p-value':>12} {'Sig':>6}\")\n",
    "    print(\"-\" * 80)\n",
    "    for p in prob_names:\n",
    "        rv = safe_vals([r['train_mse'] for r in all_results[p]['Random']])\n",
    "        sv = safe_vals([r['train_mse'] for r in all_results[p]['Sensible']])\n",
    "        if rv and sv:\n",
    "            _, pval = mannwhitneyu(rv, sv)\n",
    "            sig = sig_stars(pval)\n",
    "            print(f\"{p:<15} {np.mean(rv):>6.2f} +- {np.std(rv):>4.2f} \"\n",
    "                  f\"{np.mean(sv):>6.2f} +- {np.std(sv):>4.2f} \"\n",
    "                  f\"{pval:>12.6f} {sig:>6}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" FINAL TEST MSE\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Problem':<15} {'Random':>15} {'Sensible':>15} {'p-value':>12} {'Sig':>6}\")\n",
    "    print(\"-\" * 80)\n",
    "    for p in prob_names:\n",
    "        rv = safe_vals([r['test_mse'] for r in all_results[p]['Random']])\n",
    "        sv = safe_vals([r['test_mse'] for r in all_results[p]['Sensible']])\n",
    "        if rv and sv:\n",
    "            _, pval = mannwhitneyu(rv, sv)\n",
    "            sig = sig_stars(pval)\n",
    "            print(f\"{p:<15} {np.mean(rv):>6.2f} +- {np.std(rv):>4.2f} \"\n",
    "                  f\"{np.mean(sv):>6.2f} +- {np.std(sv):>4.2f} \"\n",
    "                  f\"{pval:>12.6f} {sig:>6}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" Significance: *** p<0.001, ** p<0.01, * p<0.05, ns = not significant\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # ==================================================================\n",
    "    # 14. PLOTS\n",
    "    # ==================================================================\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'axes.titlesize': 11,\n",
    "        'axes.labelsize': 10,\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.dpi': 300,\n",
    "        'savefig.bbox': 'tight',\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.3,\n",
    "        'lines.linewidth': 1.5,\n",
    "    })\n",
    "    n_probs = len(PROBLEMS)\n",
    "\n",
    "    # --- Fig 1: Initial Population Quality (2×2 grid) ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(\n",
    "        'Initial Population Quality: Random vs Sensible (RHH)\\n'\n",
    "        '[GRAPE parameters: Pop=200, Lazy mapper, CodonSize=255]',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for idx, (pn, res) in enumerate(all_results.items()):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        d = {m: safe_vals([r['init']['validity'] * 100 for r in res[m]])\n",
    "             for m in ['Random', 'Sensible']}\n",
    "        if d['Random'] and d['Sensible']:\n",
    "            bp = ax.boxplot(\n",
    "                [d['Random'], d['Sensible']],\n",
    "                positions=[1, 2], widths=0.6, patch_artist=True,\n",
    "                medianprops=dict(color='black', linewidth=1.5)\n",
    "            )\n",
    "            for patch, m in zip(bp['boxes'], ['Random', 'Sensible']):\n",
    "                patch.set_facecolor(COLORS[m])\n",
    "                patch.set_alpha(0.7)\n",
    "            _, p = mannwhitneyu(d['Random'], d['Sensible'])\n",
    "            ax.text(\n",
    "                1.5, ax.get_ylim()[1] * 0.97,\n",
    "                f'p={p:.4f} ({sig_stars(p)})',\n",
    "                ha='center', fontsize=8, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3',\n",
    "                          facecolor='lightyellow', alpha=0.8)\n",
    "            )\n",
    "        ax.set_xticks([1, 2])\n",
    "        ax.set_xticklabels(['Random', 'Sensible'])\n",
    "        ax.set_ylabel('Initial Validity Rate (%)')\n",
    "        ax.set_title(pn)\n",
    "        ax.set_ylim([0, 105])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig1_initial_quality.png')\n",
    "    plt.close()\n",
    "    print(\"\\nSaved: fig1_initial_quality.png\")\n",
    "\n",
    "    # --- Fig 2: Convergence curves ---\n",
    "    fig, axes = plt.subplots(n_probs, 2, figsize=(14, 4 * n_probs))\n",
    "    fig.suptitle(\n",
    "        'Convergence: Best MSE & Structural Diversity',\n",
    "        fontsize=13, fontweight='bold', y=1.01\n",
    "    )\n",
    "\n",
    "    for row, (pn, res) in enumerate(all_results.items()):\n",
    "        ng = len(res['Random'][0]['hist']['min'])\n",
    "        x_ax = np.arange(ng)\n",
    "\n",
    "        # Best MSE\n",
    "        ax = axes[row, 0]\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            c = np.array([r['hist']['min'] for r in res[m]], dtype=float)\n",
    "            c = np.where(np.isnan(c) | (c > 1e8), np.nan, c)\n",
    "            mn = np.nanmean(c, axis=0)\n",
    "            sd = np.nanstd(c, axis=0)\n",
    "            ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "            ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                            color=COLORS[m], alpha=0.15)\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_ylabel('Best MSE (train)')\n",
    "        ax.set_title(f'{pn}: Convergence')\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "        # Structural diversity\n",
    "        ax = axes[row, 1]\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            c = np.array([r['hist']['struct_div'] for r in res[m]])\n",
    "            mn = np.mean(c, axis=0)\n",
    "            sd = np.std(c, axis=0)\n",
    "            ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "            ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                            color=COLORS[m], alpha=0.15)\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_ylabel('Structural Diversity')\n",
    "        ax.set_title(f'{pn}: Diversity')\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig2_convergence.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig2_convergence.png\")\n",
    "\n",
    "    # --- Fig 3: Final fitness boxplots ---\n",
    "    fig, axes = plt.subplots(2, n_probs, figsize=(5 * n_probs, 10))\n",
    "    fig.suptitle(\n",
    "        f'Final Fitness Distribution ({N_RUNS} runs × {MAX_GENS} generations)',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_results.items()):\n",
    "        for row, (ylabel, key) in enumerate([\n",
    "            ('Train MSE', lambda r: r['train_mse']),\n",
    "            ('Test MSE', lambda r: r['test_mse']),\n",
    "        ]):\n",
    "            ax = axes[row, col]\n",
    "            d = {m: safe_vals([key(r) for r in res[m]])\n",
    "                 for m in ['Random', 'Sensible']}\n",
    "            if d['Random'] and d['Sensible']:\n",
    "                bp = ax.boxplot(\n",
    "                    [d['Random'], d['Sensible']],\n",
    "                    labels=['Random', 'Sensible'],\n",
    "                    patch_artist=True,\n",
    "                    medianprops=dict(color='black', linewidth=1.5)\n",
    "                )\n",
    "                for patch, m in zip(bp['boxes'], ['Random', 'Sensible']):\n",
    "                    patch.set_facecolor(COLORS[m])\n",
    "                    patch.set_alpha(0.7)\n",
    "                _, p = mannwhitneyu(d['Random'], d['Sensible'])\n",
    "                a_val = vda(d['Random'], d['Sensible'])\n",
    "                ax.text(\n",
    "                    1.5, ax.get_ylim()[1] * 0.97,\n",
    "                    f'p={p:.4f} ({sig_stars(p)})\\nA={a_val:.3f}',\n",
    "                    ha='center', fontsize=8, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3',\n",
    "                              facecolor='lightyellow', alpha=0.8)\n",
    "                )\n",
    "            ax.set_ylabel(ylabel)\n",
    "            if row == 0:\n",
    "                ax.set_title(pn)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig3_boxplots.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig3_boxplots.png\")\n",
    "\n",
    "    # --- Fig 4: Population structure over evolution ---\n",
    "    fig, axes = plt.subplots(2, n_probs, figsize=(5 * n_probs, 7))\n",
    "    fig.suptitle(\n",
    "        'Population Structure Over Evolution',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_results.items()):\n",
    "        ng = len(res['Random'][0]['hist']['avg_depth'])\n",
    "        x_ax = np.arange(ng)\n",
    "        for row, (ylabel, key) in enumerate([\n",
    "            ('Avg Tree Depth', 'avg_depth'),\n",
    "            ('Avg Nodes', 'avg_nodes'),\n",
    "        ]):\n",
    "            ax = axes[row, col]\n",
    "            for m in ['Random', 'Sensible']:\n",
    "                c = np.array([r['hist'][key] for r in res[m]])\n",
    "                mn = np.mean(c, axis=0)\n",
    "                sd = np.std(c, axis=0)\n",
    "                ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "                ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                                color=COLORS[m], alpha=0.15)\n",
    "            ax.set_xlabel('Generation')\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.legend(fontsize=8)\n",
    "            if row == 0:\n",
    "                ax.set_title(pn)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig4_structure.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig4_structure.png\")\n",
    "\n",
    "    # --- Fig 5: Invalid individuals over generations ---\n",
    "    fig, axes = plt.subplots(1, n_probs, figsize=(5 * n_probs, 4))\n",
    "    fig.suptitle(\n",
    "        'Invalid Individuals Over Evolution',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for col, (pn, res) in enumerate(all_results.items()):\n",
    "        ax = axes[col] if n_probs > 1 else axes\n",
    "        ng = len(res['Random'][0]['hist']['invalid'])\n",
    "        x_ax = np.arange(ng)\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            c = np.array(\n",
    "                [r['hist']['invalid'] for r in res[m]], dtype=float\n",
    "            )\n",
    "            mn = np.mean(c, axis=0)\n",
    "            sd = np.std(c, axis=0)\n",
    "            ax.plot(x_ax, mn, label=m, color=COLORS[m])\n",
    "            ax.fill_between(x_ax, mn - sd, mn + sd,\n",
    "                            color=COLORS[m], alpha=0.15)\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_ylabel('# Invalid')\n",
    "        ax.set_title(pn)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig5_invalids.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: fig5_invalids.png\")\n",
    "\n",
    "    # ==================================================================\n",
    "    # 15. BEST SOLUTIONS & SAVE DATA\n",
    "    # ==================================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" BEST SOLUTIONS FOUND\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for pn, res in all_results.items():\n",
    "        print(f\"\\n{'#' * 50}\")\n",
    "        print(f\"# {pn}\")\n",
    "        print(f\"{'#' * 50}\")\n",
    "        for m in ['Random', 'Sensible']:\n",
    "            v = [r for r in res[m]\n",
    "                 if r['train_mse'] is not None\n",
    "                 and not np.isnan(r['train_mse'])]\n",
    "            if v:\n",
    "                b = min(v, key=lambda r: r['train_mse'])\n",
    "                ph = (b['pheno'] or 'N/A')[:120]\n",
    "                print(f\"\\n  {m}:\")\n",
    "                print(f\"    Train MSE={b['train_mse']:.6f}  \"\n",
    "                      f\"Test MSE={b['test_mse']:.6f}  \"\n",
    "                      f\"Depth={b['depth']}  Nodes={b['nodes']}\")\n",
    "                print(f\"    {ph}\")\n",
    "\n",
    "    # --- Save JSON ---\n",
    "    def serialise(obj):\n",
    "        if isinstance(obj, (np.integer,)):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, (np.floating, float)):\n",
    "            return None if np.isnan(obj) else float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: serialise(v) for k, v in obj.items()}\n",
    "        if isinstance(obj, list):\n",
    "            return [serialise(v) for v in obj]\n",
    "        return obj\n",
    "\n",
    "    with open('ge_results_raw.json', 'w') as f:\n",
    "        json.dump(serialise(all_results), f)\n",
    "\n",
    "    config = {\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'source': 'GRAPE-faithful core with 4 benchmarks',\n",
    "        'parameters': {\n",
    "            'population_size': POP_SIZE,\n",
    "            'max_generations': MAX_GENS,\n",
    "            'p_crossover': P_CX,\n",
    "            'p_mutation': P_MUT,\n",
    "            'elite_size': ELITE,\n",
    "            'tournament_size': TOURN,\n",
    "            'max_tree_depth': MAX_TREE_DEPTH,\n",
    "            'codon_size': CODON_SIZE,\n",
    "            'codon_consumption': 'lazy',\n",
    "            'fitness_metric': 'MSE',\n",
    "            'random_init_genome_length': [MIN_INIT_GL, MAX_INIT_GL],\n",
    "            'sensible_init_depth': [MIN_INIT_DEPTH, MAX_INIT_DEPTH],\n",
    "            'sensible_method': 'Ramped Half-and-Half (RHH)',\n",
    "        },\n",
    "        'n_runs': N_RUNS,\n",
    "        'seed': SEED,\n",
    "        'total_seconds': total_t,\n",
    "        'problems': list(PROBLEMS.keys()),\n",
    "        'references': [\n",
    "            'Ryan & Azad (2003) Sensible initialisation in GE, GECCO',\n",
    "            'Nicolau (2017) Understanding GE: initialisation, GPEM 18(4)',\n",
    "            'de Lima et al. (2022) GRAPE, Signals 3(3), 642-663',\n",
    "            'Murphy et al. (2024) Structured GE Initialisation, GPEM 25(2)',\n",
    "        ],\n",
    "    }\n",
    "    with open('experiment_config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\" ALL DONE — {total_t / 60:.1f} min total\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    print(\" Output files:\")\n",
    "    print(\"   fig1_initial_quality.png\")\n",
    "    print(\"   fig2_convergence.png\")\n",
    "    print(\"   fig3_boxplots.png\")\n",
    "    print(\"   fig4_structure.png\")\n",
    "    print(\"   fig5_invalids.png\")\n",
    "    print(\"   ge_results_raw.json\")\n",
    "    print(\"   experiment_config.json\")\n",
    "    print(\"\\n EXPERIMENT COMPLETE!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
